---
phase: 14-narrative-director-user-interaction
plan: 04
type: execute
wave: 3
depends_on: ["14-02"]
files_modified:
  - Assets/AyaLiveStream/PushToTalkController.cs
  - Assets/AyaLiveStream/LivestreamUI.cs
  - Assets/AyaLiveStream/UI/LivestreamPanel.uxml
  - Assets/AyaLiveStream/UI/LivestreamPanel.uss
autonomous: true

must_haves:
  truths:
    - "When user presses SPACE while Aya is speaking, visual acknowledgment appears within 500ms"
    - "Aya completes her current response before addressing user input (finish-first)"
    - "After user releases SPACE, transcript overlay slides up over chat feed with 3-second auto-submit countdown"
    - "User can press Enter to submit immediately or Escape to cancel (silent discard)"
    - "Auto-submit timer sends transcript automatically after 3 seconds if user takes no action"
    - "Chat keeps flowing during PTT (only Aya pauses, not chat bots)"
    - "User transcript appears in chat feed as a user message upon submission"
  artifacts:
    - path: "Assets/AyaLiveStream/PushToTalkController.cs"
      provides: "4-state PTT machine (Idle, Recording, Reviewing, Submitted), finish-first logic, transcript approval"
      exports: ["PushToTalkController"]
      min_lines: 120
    - path: "Assets/AyaLiveStream/LivestreamUI.cs"
      provides: "Extended with transcript overlay, acknowledgment indicator, auto-submit progress methods"
      contains: "ShowTranscriptOverlay"
    - path: "Assets/AyaLiveStream/UI/LivestreamPanel.uxml"
      provides: "Transcript overlay container, acknowledgment indicator, auto-submit progress bar"
      contains: "transcript-overlay"
    - path: "Assets/AyaLiveStream/UI/LivestreamPanel.uss"
      provides: "Styles for overlay slide-up, countdown bar, acknowledgment pulse"
      contains: "transcript-overlay"
  key_links:
    - from: "PushToTalkController.cs"
      to: "PersonaSession.OnInputTranscription"
      via: "event subscription for live transcript display"
      pattern: "OnInputTranscription"
    - from: "PushToTalkController.cs"
      to: "NarrativeDirector.IsAyaSpeaking"
      via: "finish-first check on PTT press"
      pattern: "IsAyaSpeaking"
    - from: "PushToTalkController.cs"
      to: "LivestreamUI.ShowTranscriptOverlay"
      via: "showing transcript review UI"
      pattern: "ShowTranscriptOverlay"
    - from: "PushToTalkController.cs"
      to: "PersonaSession.StartListening/StopListening"
      via: "microphone control during recording state"
      pattern: "StartListening|StopListening"
---

<objective>
Create PushToTalkController with finish-first state machine (Idle, Recording, Reviewing, Submitted), transcript approval overlay with 3-second auto-submit, and visual acknowledgment when user speaks while Aya is talking. Extend LivestreamUI and UXML/USS with the overlay and acknowledgment elements.

Purpose: The user's primary interaction with Aya during the livestream. Finish-first priority ensures Aya feels natural (completes her thought) while the transcript review gives the user control over what they send. The 500ms acknowledgment prevents the user from thinking they're being ignored.

Output: PushToTalkController.cs (new), modified LivestreamUI.cs, LivestreamPanel.uxml, LivestreamPanel.uss.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-narrative-director-user-interaction/14-CONTEXT.md
@.planning/phases/14-narrative-director-user-interaction/14-RESEARCH.md
@.planning/phases/14-narrative-director-user-interaction/14-02-SUMMARY.md
@Assets/AyaLiveStream/LivestreamUI.cs
@Assets/AyaLiveStream/UI/LivestreamPanel.uxml
@Assets/AyaLiveStream/UI/LivestreamPanel.uss
@Assets/AyaLiveStream/NarrativeDirector.cs
@Assets/QueuedResponseSample/QueuedResponseController.cs
@Packages/com.google.ai-embodiment/Runtime/PersonaSession.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add transcript overlay and acknowledgment elements to UXML/USS and LivestreamUI</name>
  <files>
Assets/AyaLiveStream/UI/LivestreamPanel.uxml
Assets/AyaLiveStream/UI/LivestreamPanel.uss
Assets/AyaLiveStream/LivestreamUI.cs
  </files>
  <action>
Read all 3 files first, then modify them.

**LivestreamPanel.uxml -- Add these elements:**

1. Inside the `aya-panel` VisualElement, BEFORE the existing `ptt-area`, add an acknowledgment indicator:
```xml
<!-- PTT acknowledgment: "Aya noticed you" -->
<ui:VisualElement name="ptt-ack" class="ptt-ack ptt-ack--hidden">
    <ui:Label name="ptt-ack-text" text="Aya heard you -- finishing her thought..." class="ptt-ack-text" />
</ui:VisualElement>
```

2. Inside the `chat-panel` VisualElement, AFTER the `chat-input-area`, add a transcript overlay container that will slide up over the chat:
```xml
<!-- Transcript review overlay (slides up from bottom) -->
<ui:VisualElement name="transcript-overlay" class="transcript-overlay transcript-overlay--hidden">
    <ui:Label name="transcript-label" text="Your message:" class="transcript-label" />
    <ui:Label name="transcript-text" text="" class="transcript-text" />
    <ui:VisualElement name="transcript-actions" class="transcript-actions">
        <ui:Label name="transcript-hint" text="ENTER to send | ESC to cancel" class="transcript-hint" />
        <ui:VisualElement name="auto-submit-bar" class="auto-submit-bar">
            <ui:VisualElement name="auto-submit-fill" class="auto-submit-fill" />
        </ui:VisualElement>
    </ui:VisualElement>
</ui:VisualElement>
```

**LivestreamPanel.uss -- Add these styles:**

```css
/* PTT Acknowledgment ("Aya noticed you") */
.ptt-ack {
    padding: 6px 10px;
    background-color: rgba(100, 200, 255, 0.15);
    border-radius: 6px;
    margin-bottom: 4px;
    transition-property: opacity;
    transition-duration: 200ms;
}

.ptt-ack--hidden {
    opacity: 0;
    display: none;
}

.ptt-ack--visible {
    opacity: 1;
    display: flex;
}

.ptt-ack-text {
    color: rgb(100, 200, 255);
    font-size: 12px;
    -unity-font-style: italic;
}

/* Transcript Review Overlay */
.transcript-overlay {
    position: absolute;
    bottom: 0;
    left: 0;
    right: 0;
    background-color: rgba(24, 24, 40, 0.95);
    border-top-left-radius: 12px;
    border-top-right-radius: 12px;
    padding: 12px 16px;
    transition-property: translate;
    transition-duration: 300ms;
}

.transcript-overlay--hidden {
    display: none;
    translate: 0 100%;
}

.transcript-overlay--visible {
    display: flex;
    translate: 0 0;
}

.transcript-label {
    color: rgb(140, 140, 160);
    font-size: 11px;
    margin-bottom: 4px;
}

.transcript-text {
    color: rgb(220, 220, 240);
    font-size: 14px;
    white-space: normal;
    margin-bottom: 8px;
    min-height: 20px;
}

.transcript-actions {
    flex-direction: row;
    justify-content: space-between;
    align-items: center;
}

.transcript-hint {
    color: rgb(100, 100, 130);
    font-size: 11px;
}

/* Auto-submit countdown bar */
.auto-submit-bar {
    width: 80px;
    height: 4px;
    background-color: rgb(40, 40, 60);
    border-radius: 2px;
    overflow: hidden;
}

.auto-submit-fill {
    height: 100%;
    background-color: rgb(100, 200, 255);
    width: 100%;
    transition-property: width;
    transition-duration: 100ms;
}
```

Also make the chat-panel position relative so the absolute-positioned overlay works:
```css
.chat-panel {
    /* ADD to existing rule: */
    position: relative;
}
```

**LivestreamUI.cs -- Add UI binding and public API methods:**

Read the existing file first. Add these private fields after the existing ones:
```csharp
// Transcript overlay elements
private VisualElement _transcriptOverlay;
private Label _transcriptText;
private VisualElement _autoSubmitFill;

// PTT acknowledgment
private VisualElement _pttAck;
```

In OnEnable(), after existing element queries, add:
```csharp
_transcriptOverlay = root.Q("transcript-overlay");
_transcriptText = root.Q<Label>("transcript-text");
_autoSubmitFill = root.Q("auto-submit-fill");
_pttAck = root.Q("ptt-ack");
```

Add these public methods:

```csharp
/// <summary>
/// Shows or hides the "Aya noticed you" acknowledgment indicator.
/// Uses CSS class toggle for synchronous, frame-immediate update (<500ms).
/// </summary>
public void ShowPTTAcknowledgment(bool show)
{
    if (_pttAck == null) return;
    if (show)
    {
        _pttAck.RemoveFromClassList("ptt-ack--hidden");
        _pttAck.AddToClassList("ptt-ack--visible");
    }
    else
    {
        _pttAck.RemoveFromClassList("ptt-ack--visible");
        _pttAck.AddToClassList("ptt-ack--hidden");
    }
}

/// <summary>
/// Shows or hides the transcript review overlay.
/// </summary>
public void ShowTranscriptOverlay(bool show)
{
    if (_transcriptOverlay == null) return;
    if (show)
    {
        _transcriptOverlay.RemoveFromClassList("transcript-overlay--hidden");
        _transcriptOverlay.AddToClassList("transcript-overlay--visible");
    }
    else
    {
        _transcriptOverlay.RemoveFromClassList("transcript-overlay--visible");
        _transcriptOverlay.AddToClassList("transcript-overlay--hidden");
    }
}

/// <summary>
/// Sets the transcript text displayed in the review overlay.
/// </summary>
public void SetTranscriptText(string text)
{
    if (_transcriptText != null) _transcriptText.text = text;
}

/// <summary>
/// Updates the auto-submit countdown progress bar.
/// </summary>
/// <param name="progress">0.0 (empty) to 1.0 (full).</param>
public void UpdateAutoSubmitProgress(float progress)
{
    if (_autoSubmitFill != null)
    {
        _autoSubmitFill.style.width = new StyleLength(Length.Percent(Mathf.Clamp01(progress) * 100f));
    }
}
```

Do NOT remove or modify any existing methods. This is purely additive.
  </action>
  <verify>
All 3 files compile/parse correctly. LivestreamPanel.uxml has `transcript-overlay` and `ptt-ack` elements. LivestreamPanel.uss has styles for both. LivestreamUI.cs has ShowPTTAcknowledgment, ShowTranscriptOverlay, SetTranscriptText, UpdateAutoSubmitProgress methods.
  </verify>
  <done>LivestreamUI extended with transcript overlay and acknowledgment indicator. UXML has the elements, USS has dark-theme styles with slide-up transition and countdown bar, LivestreamUI.cs has the binding and public API.</done>
</task>

<task type="auto">
  <name>Task 2: Create PushToTalkController with finish-first state machine and transcript approval</name>
  <files>Assets/AyaLiveStream/PushToTalkController.cs</files>
  <action>
Create PushToTalkController.cs in the AIEmbodiment.Samples namespace as a MonoBehaviour. Reference the QueuedResponseController pattern for state machine structure.

**State machine (4 states):**
```
Idle -> Recording (SPACE pressed)
Recording -> Reviewing (SPACE released)
Reviewing -> Submitted (Enter pressed OR 3s auto-submit)
Reviewing -> Idle (Escape pressed -- silent discard)
Submitted -> Idle (Aya turn complete)
```

**Serialized fields:**
- `[SerializeField] PersonaSession _session`
- `[SerializeField] NarrativeDirector _narrativeDirector`
- `[SerializeField] LivestreamUI _livestreamUI`
- `[SerializeField] ChatBotManager _chatBotManager` -- for posting user message to chat feed

**Private state:**
- `PTTState _state = PTTState.Idle` (private enum: Idle, Recording, Reviewing, Submitted)
- `string _transcript = ""`
- `float _autoSubmitTimer`
- `const float AutoSubmitDelay = 3f`
- `bool _ayaWasSpeakingOnPress` -- tracks if Aya was speaking when user started recording

**Event subscriptions (Start/OnDestroy):**
- `_session.OnInputTranscription += HandleTranscription`
- `_session.OnTurnComplete += HandleTurnComplete`

**HandleTranscription(string text):**
If `_state == Recording || _state == Reviewing`:
  - `_transcript = text`
  - `_livestreamUI.SetTranscriptText(text)` (live update during recording)

**HandleTurnComplete():**
If `_state == Submitted`:
  - Reset to Idle state
  - `_livestreamUI.ShowPTTAcknowledgment(false)`
  - `_livestreamUI.ShowTranscriptOverlay(false)`
  - `_livestreamUI.SetPTTStatus("Hold SPACE to talk", active: false)`

**Update() state machine:**
```csharp
private void Update()
{
    if (Keyboard.current == null) return;

    switch (_state)
    {
        case PTTState.Idle:
            if (Keyboard.current.spaceKey.wasPressedThisFrame)
                EnterRecording();
            break;

        case PTTState.Recording:
            if (Keyboard.current.spaceKey.wasReleasedThisFrame)
                EnterReviewing();
            break;

        case PTTState.Reviewing:
            UpdateReviewState();
            break;

        case PTTState.Submitted:
            // Waiting for HandleTurnComplete to reset to Idle
            break;
    }
}
```

**EnterRecording():**
```csharp
private void EnterRecording()
{
    _state = PTTState.Recording;
    _transcript = "";

    // Show acknowledgment immediately if Aya is speaking (USR-02: <500ms requirement)
    // CSS class toggle is synchronous and frame-immediate -- no async delay
    _ayaWasSpeakingOnPress = _narrativeDirector != null && _narrativeDirector.IsAyaSpeaking;
    if (_ayaWasSpeakingOnPress)
    {
        _livestreamUI.ShowPTTAcknowledgment(true);
    }

    _session.StartListening();
    _livestreamUI.SetPTTStatus("Recording...", active: true);
}
```

**EnterReviewing():**
```csharp
private void EnterReviewing()
{
    _state = PTTState.Reviewing;
    _session.StopListening(); // Sends audioStreamEnd, triggers Gemini STT

    _autoSubmitTimer = AutoSubmitDelay;

    // Transcript overlay slides up over chat feed
    _livestreamUI.ShowTranscriptOverlay(true);
    _livestreamUI.SetTranscriptText(_transcript);
    _livestreamUI.UpdateAutoSubmitProgress(1f);
    _livestreamUI.SetPTTStatus("Review your message", active: false);
}
```

**UpdateReviewState():**
```csharp
private void UpdateReviewState()
{
    // Auto-submit countdown
    _autoSubmitTimer -= Time.deltaTime;
    _livestreamUI.UpdateAutoSubmitProgress(_autoSubmitTimer / AutoSubmitDelay);

    if (_autoSubmitTimer <= 0f)
    {
        SubmitTranscript();
        return;
    }

    // Manual submit (Enter)
    if (Keyboard.current.enterKey.wasPressedThisFrame)
    {
        SubmitTranscript();
        return;
    }

    // Cancel (Escape) -- silent discard, no feedback animation (per CONTEXT.md)
    if (Keyboard.current.escapeKey.wasPressedThisFrame)
    {
        CancelTranscript();
        return;
    }
}
```

**SubmitTranscript():**
```csharp
private void SubmitTranscript()
{
    // Idempotent guard (Pitfall 6: double submission from Enter + timer)
    if (_state == PTTState.Submitted) return;

    _state = PTTState.Submitted;

    // Post user message to chat feed so other viewers can see it
    if (_livestreamUI != null && !string.IsNullOrWhiteSpace(_transcript))
    {
        _livestreamUI.AddMessage(ChatMessage.FromUser(_transcript));
    }

    // Hide overlay -- the transcript has been "sent"
    _livestreamUI.ShowTranscriptOverlay(false);
    _livestreamUI.SetPTTStatus("Aya is responding...", active: false);

    // NOTE: The actual user speech audio has already been sent to Gemini during Recording.
    // StopListening triggered the STT pipeline. Gemini will respond when ready.
    // If Aya was speaking (finish-first), Gemini queues the user input and responds
    // after Aya's current turn completes.
    // We wait in Submitted state for HandleTurnComplete to reset to Idle.

    // If Aya was NOT speaking when we pressed PTT, she's already processing.
    // If Aya WAS speaking, the Gemini Live API handles the finish-first naturally
    // via its built-in VAD and turn management.
}
```

**CancelTranscript():**
```csharp
private void CancelTranscript()
{
    _state = PTTState.Idle;
    _transcript = "";
    _livestreamUI.ShowTranscriptOverlay(false);
    _livestreamUI.ShowPTTAcknowledgment(false);
    _livestreamUI.SetPTTStatus("Hold SPACE to talk", active: false);
}
```

**OnDestroy():**
Unsubscribe events (null-check _session):
```csharp
private void OnDestroy()
{
    if (_session != null)
    {
        _session.OnInputTranscription -= HandleTranscription;
        _session.OnTurnComplete -= HandleTurnComplete;
    }
}
```

**Private enum (inside the class):**
```csharp
private enum PTTState { Idle, Recording, Reviewing, Submitted }
```

**Required using directives:**
- `using UnityEngine;`
- `using UnityEngine.InputSystem;`
- `using AIEmbodiment;`

CRITICAL NOTES:
- Do NOT directly interact with the audio stream. PersonaSession.StartListening/StopListening handles all mic and Gemini audio communication.
- The 500ms acknowledgment requirement is met by a synchronous CSS class toggle (no async) -- this happens in the same frame as the key press.
- Auto-submit and Enter are both routed through SubmitTranscript with an idempotent guard to prevent double submission (Pitfall 6).
- Chat keeps flowing during PTT -- PushToTalkController does NOT pause ChatBotManager (per CONTEXT.md: "Only Aya pauses during PTT").
  </action>
  <verify>
PushToTalkController.cs compiles. Verify: 4-state machine (Idle, Recording, Reviewing, Submitted), EnterRecording checks IsAyaSpeaking for acknowledgment, SubmitTranscript has idempotent guard, HandleTurnComplete resets to Idle, OnDestroy unsubscribes events, uses Keyboard.current for input.
  </verify>
  <done>PushToTalkController implements finish-first PTT with: immediate acknowledgment when Aya is speaking (<500ms), transcript review overlay with 3-second auto-submit countdown, Enter to send immediately, Escape to cancel silently, idempotent submission guard, and proper event lifecycle.</done>
</task>

</tasks>

<verification>
1. SPACE press while Aya speaks shows "Aya heard you -- finishing her thought..." indicator immediately
2. SPACE release shows transcript overlay with countdown bar
3. Auto-submit fires after 3 seconds with no user action
4. Enter submits immediately (cancels timer implicitly via state transition)
5. Escape cancels silently (no animation, no feedback)
6. User message appears in chat feed on submit
7. No double-submission from Enter + timer race condition
8. PTT does NOT pause ChatBotManager (chat keeps flowing)
9. All events properly subscribed in Start and unsubscribed in OnDestroy
10. Transcript overlay styles match dark theme (rgba(24,24,40,0.95) background)
</verification>

<success_criteria>
- Visual acknowledgment appears within 500ms (same-frame CSS toggle)
- Aya finishes her current response before addressing user input (finish-first)
- User can review transcript and approve/cancel before sending
- 3-second auto-submit countdown works with progress bar
- Submit and cancel are distinct, predictable actions
- All UI additions are additive -- existing LivestreamUI API preserved
</success_criteria>

<output>
After completion, create `.planning/phases/14-narrative-director-user-interaction/14-04-SUMMARY.md`
</output>
