# Phase 16.1: User-Priority Interaction - Research

**Researched:** 2026-02-17
**Domain:** Unity MonoBehaviour state machine modification, user silence tracking, priority queue logic, NarrativeDirector behavior gating, LivestreamController timer coordination
**Confidence:** HIGH

## Summary

Phase 16.1 is a behavioral refinement of the existing Phase 16 livestream experience. No new external dependencies, no new classes -- the work is modifying the interaction model inside LivestreamController, NarrativeDirector, and potentially ChatBotManager so that the user (via push-to-talk) is the primary conversation partner and bots are a fallback for dead air.

The current system has NarrativeDirector driving beats linearly: it sends director notes, executes AyaChecksChat scenes that inject bot messages into Aya's context, and progresses through scenes on timers. The problem is that this means Aya is constantly being steered by scripted narrative beats and responding to bot messages, leaving the user feeling like a spectator rather than the main participant.

The fix requires three coordinated changes:
1. **Greeting-then-drawing mode**: After the initial greeting scene, Aya enters a drawing-focused state where she talks about her art process naturally rather than being driven by rapid narrative scene progression. The NarrativeDirector still runs but AyaChecksChat scenes are gated by the user silence timer.
2. **User silence timer**: A new timer in LivestreamController tracks how long since the user last spoke via PTT. This timer resets on every OnUserSpeakingStopped event. When the timer exceeds 2 minutes (configurable), NarrativeDirector is "unblocked" to let AyaChecksChat scenes process bot messages.
3. **Priority enforcement in AyaChecksChat**: The existing code already prioritizes user messages over bot messages (line 408-417 of NarrativeDirector.cs). The new behavior adds a gate: if the user silence timer has NOT expired, AyaChecksChat skips bot messages entirely and only processes user messages (which arrive via the chat feed from PTT submit).

The key insight is that **the existing architecture already has the right seams**. NarrativeDirector.ExecuteAyaChecksChat already separates user messages from bot messages. LivestreamController already tracks PersonaSession events. PushToTalkController already posts user messages to the chat feed via `ChatMessage.FromUser()`. The changes are additions to existing methods, not replacements.

**Primary recommendation:** Add a `_lastUserSpeechTime` float and `_userSilenceThreshold` SerializeField (default 120f) to LivestreamController. Subscribe to `PersonaSession.OnUserSpeakingStopped` to reset the timer. Expose a `bool IsUserSilent` property that NarrativeDirector reads. In NarrativeDirector.ExecuteAyaChecksChat, when `IsUserSilent` is false, skip bot messages (only process user messages from the tracked queue). The greeting scene runs normally as the first beat scene, then Aya settles into drawing mode by the director note framing.

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| LivestreamController | Phase 16 | Orchestrator -- will host user silence timer | Already owns cross-system state and event subscriptions |
| NarrativeDirector | Phase 14 | Beat loop and AyaChecksChat -- will gate bot message injection | Already separates user/bot messages in ExecuteAyaChecksChat |
| PushToTalkController | Phase 14 | User PTT state machine -- already posts user chat messages | No modifications needed -- already fires OnUserSpeakingStopped |
| ChatBotManager | Phase 13 | Bot bursts continue unmodified -- bots still post to chat | No modifications needed -- bots are visual-only, not gated |
| PersonaSession | Package | OnUserSpeakingStopped event for timer reset | Existing event, no package changes |
| TrackedChatMessage | Phase 13 | ChatMessage.IsFromUser flag for priority filtering | Already has IsFromUser field |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| Time.time | Unity | Timer tracking for user silence | Standard Unity time source, consistent with existing dead air tracking |
| NarrativeBeatConfig | Phase 14 | Beat director notes -- warm-up note needs drawing focus framing | Modify directorNote content, not code |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| LivestreamController hosting the timer | NarrativeDirector hosting the timer | LivestreamController already subscribes to PersonaSession events and manages cross-system state; putting the timer there follows the established pattern and avoids adding PersonaSession dependencies to NarrativeDirector beyond what it already has |
| Gating AyaChecksChat execution | Pausing NarrativeDirector entirely | Too aggressive -- beats should still progress on time. Only bot message injection should be gated, not the entire beat lifecycle |
| Bool property IsUserSilent | Event-based OnUserBecameSilent | Event would add complexity for a single consumer. Polling a bool in the AyaChecksChat path is simpler and the method already awaits between operations |
| Modifying NarrativeDirector to read LivestreamController | Callback injection via SetUserSilenceProvider | A Func<bool> callback avoids a direct reference from NarrativeDirector to LivestreamController; follows the same injection pattern as SetFactTracker |

## Architecture Patterns

### Recommended Project Structure
```
Assets/AyaLiveStream/
  LivestreamController.cs       # MODIFIED -- add user silence timer, expose IsUserSilent
  NarrativeDirector.cs          # MODIFIED -- gate AyaChecksChat bot injection on user silence
  NarrativeBeatConfig.cs        # UNCHANGED -- no code changes needed
  PushToTalkController.cs       # UNCHANGED -- already fires the right events
  ChatBotManager.cs             # UNCHANGED -- bots keep posting, they're visual-only
  LivestreamUI.cs               # UNCHANGED -- no new UI elements needed
  Data/
    Beat_WarmUp.asset           # MODIFIED -- directorNote reframed for drawing focus
    Beat_ArtProcess.asset       # MODIFIED -- directorNote reframed for drawing focus
    Beat_Characters.asset       # MODIFIED -- directorNote adjusted for user-priority context
```

### Pattern 1: User Silence Timer in LivestreamController
**What:** LivestreamController tracks when the user last spoke via PTT. A `bool IsUserSilent` property returns true when the silence exceeds a configurable threshold (default 120 seconds). The timer resets every time the user speaks.
**When to use:** Always -- this is the core state that gates bot message injection.
**Example:**
```csharp
// Source: extends existing LivestreamController (Assets/AyaLiveStream/LivestreamController.cs)
// New fields:
[Header("User Priority")]
[SerializeField] private float _userSilenceThreshold = 120f;

private float _lastUserSpeechTime;
private Action _onUserSpeakingStopped;

// In Start(), after existing event subscriptions:
_lastUserSpeechTime = Time.time; // Start silent (allow greeting, then timer starts)
_onUserSpeakingStopped = HandleUserSpeakingStopped;
if (_session != null)
{
    _session.OnUserSpeakingStopped += _onUserSpeakingStopped;
}

// Inject the silence check into NarrativeDirector:
_narrativeDirector?.SetUserSilenceProvider(() => UserSilenceDuration >= _userSilenceThreshold);

// New handler:
private void HandleUserSpeakingStopped()
{
    _lastUserSpeechTime = Time.time;
}

// Property for diagnostics:
private float UserSilenceDuration => Time.time - _lastUserSpeechTime;

// In OnDestroy(), add:
if (_session != null && _onUserSpeakingStopped != null)
    _session.OnUserSpeakingStopped -= _onUserSpeakingStopped;
```

### Pattern 2: Func<bool> Injection into NarrativeDirector
**What:** NarrativeDirector receives a `Func<bool>` callback that returns true when the user has been silent long enough for bot messages to be processed. This follows the same dependency injection pattern as `SetFactTracker(FactTracker)` -- a public setter that the orchestrator calls in Start().
**When to use:** When NarrativeDirector needs to know about user silence without depending directly on LivestreamController.
**Example:**
```csharp
// Source: extends NarrativeDirector (Assets/AyaLiveStream/NarrativeDirector.cs)
// New field:
private Func<bool> _isUserSilent;

// New public setter (same pattern as SetFactTracker):
/// <summary>
/// Injects a callback that returns true when the user has been silent
/// long enough that Aya should engage with bot messages. When the callback
/// returns false, AyaChecksChat will skip bot messages and only process
/// user messages. Called by LivestreamController in Start().
/// </summary>
public void SetUserSilenceProvider(Func<bool> isUserSilent)
{
    _isUserSilent = isUserSilent;
}
```

### Pattern 3: Gated AyaChecksChat Execution
**What:** The existing ExecuteAyaChecksChat method already separates user messages from bot messages (lines 408-417). The modification adds a gate: when the user silence provider returns false (user is active or has recently been active), bot messages are skipped entirely. User messages are always processed regardless of the timer.
**When to use:** Every time ExecuteAyaChecksChat runs.
**Example:**
```csharp
// Source: modifies NarrativeDirector.ExecuteAyaChecksChat
// (Assets/AyaLiveStream/NarrativeDirector.cs lines 397-441)
private async Awaitable ExecuteAyaChecksChat(NarrativeSceneConfig scene)
{
    if (_chatBotManager == null) return;

    var unresponded = _chatBotManager.GetUnrespondedMessages();
    if (unresponded.Count == 0)
    {
        Debug.Log($"[NarrativeDirector] AyaChecksChat '{scene.sceneId}': no unresponded messages");
        return;
    }

    // Separate user and bot messages (existing logic)
    var userMessages = new List<TrackedChatMessage>();
    var botMessages = new List<TrackedChatMessage>();
    foreach (var msg in unresponded)
    {
        if (msg.Message.IsFromUser) userMessages.Add(msg);
        else botMessages.Add(msg);
    }

    // USER PRIORITY GATE: Only process bot messages if user has been silent
    // long enough. User messages always get through.
    List<TrackedChatMessage> toAddress;
    if (userMessages.Count > 0)
    {
        toAddress = userMessages;
    }
    else if (_isUserSilent != null && _isUserSilent())
    {
        // User has been silent for the threshold -- bots can get attention
        toAddress = botMessages;
    }
    else
    {
        // User is active (or recently active) and no user messages queued.
        // Skip bot messages -- Aya stays focused on drawing.
        Debug.Log($"[NarrativeDirector] AyaChecksChat '{scene.sceneId}': " +
                  "user active, skipping bot messages");
        return;
    }

    // ... rest of existing method (summary builder, SendText, WaitForTurnComplete) ...
}
```

### Pattern 4: Drawing-Focus Director Notes
**What:** The Beat_WarmUp directorNote and first beat scenes are reframed so that after the greeting, Aya naturally settles into her drawing activity and talks about her art process. She does not aggressively drive narrative -- she focuses on creating and only engages when prompted by the user or (after silence) by the bots.
**When to use:** Asset modification only -- no code changes. Edit the .asset YAML files or use the Inspector.
**Example director note adjustment:**
```
// Current Beat_WarmUp directorNote:
[Director: You're just starting your art livestream. Greet your audience
warmly, introduce yourself as Aya, and chat casually about your day
and what you're planning to work on today. Be friendly and approachable.]

// Modified for user-priority:
[Director: You're just starting your art livestream. Greet your audience
warmly, then settle into your drawing. You're focused on your art --
talk about what you're working on when it feels natural, but your primary
activity is drawing. If a viewer talks to you directly, always engage
with them enthusiastically. Between viewer interactions, you can comment
on your art, hum, or think aloud -- but don't force conversation.
Let the viewer drive the chat.]
```

### Anti-Patterns to Avoid
- **Pausing ChatBotManager during user activity:** Bots should keep posting to the chat feed regardless of user activity. They are "visual-only" -- their messages populate the chat feed for ambiance. The gate is on whether Aya READS and RESPONDS to bot messages, not whether bots post them.
- **Resetting the user silence timer on bot messages:** The timer tracks USER silence specifically. Bot messages are ambient and should not affect the timer. This is the same principle as the existing dead air tracker (dead air = Aya silence, not bot silence).
- **Blocking NarrativeDirector beat progression:** Beats should still advance on their time budget. The gate only affects AyaChecksChat scenes within beats. AyaDialogue scenes (director notes) still execute normally. The narrative arc progresses regardless of user activity.
- **Adding a new PTT event:** PushToTalkController already fires `PersonaSession.OnUserSpeakingStopped` (via StopListening). Do not add a duplicate event. LivestreamController subscribes to the existing event.
- **Modifying PushToTalkController:** The PTT controller is self-contained and correct. No changes needed. The user silence timer lives in LivestreamController, not PushToTalkController.

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| User speech detection | Custom audio level monitoring | PersonaSession.OnUserSpeakingStopped event | Already fires when user releases PTT and StopListening is called |
| User/bot message separation | Custom message tagging system | TrackedChatMessage.Message.IsFromUser (existing) | Already distinguishes user messages from bot messages |
| Bot message injection gating | Custom queue between ChatBotManager and NarrativeDirector | Gate inside existing ExecuteAyaChecksChat method | The separation point already exists at lines 408-417 |
| Timer implementation | Custom coroutine or async timer | Simple Time.time subtraction | Dead air detection in LivestreamController already uses this exact pattern |
| Cross-system state sharing | Singleton or static global | Func<bool> callback injection via setter | Follows SetFactTracker pattern, avoids tight coupling |
| Greeting behavior | Custom greeting system | Existing Beat_WarmUp first scene (WARMUP_GREET) | Director note content change, not code change |

**Key insight:** The entire phase is achievable by adding ~30 lines of new code across 2 files (LivestreamController, NarrativeDirector) and modifying 3 beat asset director notes. The architecture already has all the seams in the right places.

## Common Pitfalls

### Pitfall 1: Timer Starts at Zero (Aya Never Greets)
**What goes wrong:** If `_lastUserSpeechTime` is initialized to `float.MinValue` or 0, the user silence check `Time.time - _lastUserSpeechTime >= threshold` is immediately true on startup. Aya would start responding to bot messages right away, defeating the purpose.
**Why it happens:** Incorrect timer initialization.
**How to avoid:** Initialize `_lastUserSpeechTime = Time.time` in Start(). This means the "user silence" clock starts when the experience begins. The 2-minute window gives the user time to get comfortable and use PTT before Aya starts engaging bots. If the user speaks at any point, the timer resets.
**Warning signs:** Aya responds to bot messages in the first 30 seconds despite the user being present.

### Pitfall 2: User Messages Never Reach AyaChecksChat
**What goes wrong:** The user speaks via PTT, the transcript is posted to the chat feed via `ChatMessage.FromUser()`, but AyaChecksChat never picks it up because the message is not in `ChatBotManager.GetUnrespondedMessages()`.
**Why it happens:** PushToTalkController posts user messages to `LivestreamUI.AddMessage()` (the visual chat feed) but does NOT add them to `ChatBotManager._trackedMessages` (the tracked message queue that NarrativeDirector reads).
**How to avoid:** This is actually the CURRENT behavior and is BY DESIGN. User PTT audio goes directly to Gemini via the Live WebSocket (PersonaSession.StartListening/StopListening). Aya responds to the user's speech audio, not to a chat message. The `ChatMessage.FromUser()` call in PushToTalkController.SubmitTranscript (line 211-213) is only for visual display in the chat feed. AyaChecksChat processes BOT messages that Aya hasn't acknowledged yet. User interaction happens through the audio channel, not the chat channel.
**Warning signs:** None -- this is correct. But a developer might mistakenly try to route user messages through the tracked message queue, which would create a double-response (Aya responds via audio AND via AyaChecksChat).

### Pitfall 3: AyaChecksChat Blocks Beat Progression When User Is Active
**What goes wrong:** If ExecuteAyaChecksChat returns early (no messages to process because user is active), the scene still occupies time in the beat. The next scene waits for the AyaChecksChat to "complete" including the WaitForTurnComplete at the end.
**Why it happens:** The early return skips SendText and WaitForTurnComplete, so the method returns immediately. This is actually CORRECT behavior -- the method returns quickly, and the beat loop moves to the next scene.
**How to avoid:** The existing flow already handles this correctly. When ExecuteAyaChecksChat returns early (no messages or user-active skip), it returns without awaiting anything, so the beat progresses to the next scene immediately. No additional handling needed.
**Warning signs:** None expected, but verify: beat timer should not stall when AyaChecksChat skips.

### Pitfall 4: User Silence Timer Not Reset During WaitingForAya State
**What goes wrong:** User presses SPACE while Aya is speaking (enters WaitingForAya state), then releases SPACE before Aya finishes (cancels deferred recording). OnUserSpeakingStopped never fires because StopListening was never called. The user "tried to speak" but the timer was not reset.
**Why it happens:** The WaitingForAya -> Idle transition in PushToTalkController (line 101-107) does not call StopListening because recording never started. OnUserSpeakingStopped therefore never fires.
**How to avoid:** This is a MINOR edge case. The user expressed intent but did not actually speak. Two options: (a) Accept the behavior -- the user didn't actually speak, so the timer shouldn't reset. (b) Add a separate "user attempted PTT" event. Option (a) is simpler and more correct -- the user silence timer tracks actual speech, not intent.
**Warning signs:** User presses and releases SPACE during Aya's speech, but the 2-minute timer does not reset. This is technically correct behavior.

### Pitfall 5: Director Notes Still Drive Aggressive Narrative Despite Timer Gate
**What goes wrong:** The AyaChecksChat gate prevents Aya from responding to bot messages, but AyaDialogue scenes still fire SendText director notes that push Aya to talk about specific topics. Aya ends up monologuing about narrative topics without user input, which defeats the user-priority goal.
**Why it happens:** AyaDialogue scenes are not gated by the user silence timer -- only AyaChecksChat is.
**How to avoid:** The director notes (in beat .asset files) need to be reframed to emphasize "drawing focus" and "respond when prompted." The beat structure stays the same, but the TONE of director notes changes from "drive conversation" to "focus on your art, engage when spoken to." This is a content authoring change, not a code change. The beat still has AyaDialogue scenes, but the notes say things like "continue working on your drawing and share occasional thoughts about your process" rather than "tell viewers about X."
**Warning signs:** Aya talks non-stop about narrative topics even when the user is actively trying to have a different conversation.

### Pitfall 6: Existing Dead Air Detection Conflicts with User Silence Timer
**What goes wrong:** LivestreamController's existing dead air detection (MonitorDeadAir, threshold 10s) triggers bot re-engagement independently of the user silence timer (120s). If dead air fires at 10s but user silence requires 120s, there's a conceptual conflict about when Aya should engage with bots.
**Why it happens:** Two different timers with different purposes: dead air prevents awkward silence (short threshold), user silence controls when Aya reads bot messages (long threshold). They serve different functions.
**How to avoid:** Clarify the distinction: Dead air detection is about VISUAL feedback (showing "Aya is thinking..." indicator) and letting the natural bot burst loop fire to fill silence. It does NOT cause Aya to respond to bot messages -- it just ensures bots keep chatting. The user silence timer gates whether AyaChecksChat injects bot messages into Aya's context. These are complementary, not conflicting: bots chat for ambiance (dead air), Aya reads bot chat only after user silence (user priority).
**Warning signs:** Developer confusion about two different silence-related timers.

## Code Examples

Verified patterns from the existing codebase that the implementation will extend:

### Complete LivestreamController Modification
```csharp
// Source: extends LivestreamController.cs
// (Assets/AyaLiveStream/LivestreamController.cs)

// --- New fields (add to Configuration header or new "User Priority" header) ---
[Header("User Priority")]
[SerializeField] private float _userSilenceThreshold = 120f;

private float _lastUserSpeechTime;
private Action _onUserSpeakingStopped;

// --- In Start(), after existing event subscriptions ---
// Initialize user silence timer (starts at experience start time,
// giving the user 2 minutes to engage before bots get attention)
_lastUserSpeechTime = Time.time;

// Subscribe to user speech for timer reset
_onUserSpeakingStopped = () => { _lastUserSpeechTime = Time.time; };
if (_session != null)
{
    _session.OnUserSpeakingStopped += _onUserSpeakingStopped;
}

// Inject user silence check into NarrativeDirector
_narrativeDirector?.SetUserSilenceProvider(
    () => Time.time - _lastUserSpeechTime >= _userSilenceThreshold);

// --- In OnDestroy(), add to existing _session unsubscribe block ---
if (_onUserSpeakingStopped != null)
    _session.OnUserSpeakingStopped -= _onUserSpeakingStopped;
```

### Complete NarrativeDirector Modification
```csharp
// Source: extends NarrativeDirector.cs
// (Assets/AyaLiveStream/NarrativeDirector.cs)

// --- New field ---
private Func<bool> _isUserSilent;

// --- New public setter ---
public void SetUserSilenceProvider(Func<bool> isUserSilent)
{
    _isUserSilent = isUserSilent;
}

// --- Modified ExecuteAyaChecksChat (only the message selection logic changes) ---
// Replace lines 408-417 with:
var userMessages = new List<TrackedChatMessage>();
var botMessages = new List<TrackedChatMessage>();
foreach (var msg in unresponded)
{
    if (msg.Message.IsFromUser) userMessages.Add(msg);
    else botMessages.Add(msg);
}

// User messages always get through (user priority)
// Bot messages only get through if user has been silent for the threshold
List<TrackedChatMessage> toAddress;
if (userMessages.Count > 0)
{
    toAddress = userMessages;
}
else if (_isUserSilent == null || _isUserSilent())
{
    toAddress = botMessages;
}
else
{
    Debug.Log($"[NarrativeDirector] AyaChecksChat '{scene.sceneId}': " +
              "user recently active, skipping bot messages");
    return;
}
// Rest of method continues with toAddress (unchanged from line 418 onward)
```

### Director Note Reframing Examples
```yaml
# Beat_WarmUp.asset directorNote (BEFORE):
# [Director: You're just starting your art livestream. Greet your audience
#  warmly, introduce yourself as Aya, and chat casually about your day
#  and what you're planning to work on today. Be friendly and approachable.]

# Beat_WarmUp.asset directorNote (AFTER):
# [Director: You're just starting your art livestream. Greet your audience
#  warmly, introduce yourself as Aya, and mention what you're working on
#  today. Then settle into your drawing -- your main focus is creating art.
#  Talk about your process occasionally, but don't force conversation.
#  If a viewer speaks to you directly, engage with them enthusiastically
#  and give them your full attention. Between viewer interactions, you can
#  comment on your art, hum, or think aloud naturally.]
```

## State of the Art

| Old Approach (Phase 16) | New Approach (Phase 16.1) | What Changes | Impact |
|--------------------------|---------------------------|--------------|--------|
| NarrativeDirector drives Aya through beats with constant AyaChecksChat bot injection | AyaChecksChat gates bot injection behind user silence timer | ~10 lines in NarrativeDirector.ExecuteAyaChecksChat | Aya focuses on user when active, falls back to bots during silence |
| No user silence tracking | LivestreamController tracks last PTT time | ~15 lines in LivestreamController | Central state for user-priority behavior |
| Director notes push Aya to drive conversation | Director notes emphasize drawing focus with user-responsive engagement | 3 asset file edits | Aya feels more like an artist who happens to stream, not a talk show host |
| Aya responds to all messages in AyaChecksChat | Aya responds to user messages always, bot messages only after 2min silence | Conditional in ExecuteAyaChecksChat | User gets priority attention |

**Unchanged (confirmed still correct):**
- ChatBotManager burst loop continues unchanged -- bots post for ambiance
- PushToTalkController unchanged -- already fires correct events
- Dead air detection unchanged -- complementary to user silence timer
- SceneTransitionHandler unchanged -- still triggers on OnAllBeatsComplete
- TrackedChatMessage and ChatMessage unchanged -- IsFromUser flag already exists

## Interaction Model Diagram

```
User PTT Event Flow (UNCHANGED):
  User presses SPACE -> PushToTalkController -> PersonaSession.StartListening
  User releases SPACE -> StopListening -> Gemini processes audio -> Aya responds
  OnUserSpeakingStopped fires -> ChatBotManager dynamic responses
                               -> LivestreamController resets silence timer (NEW)

Bot Message Flow (GATED):
  ChatBotManager posts bot messages to chat feed (UNCHANGED -- always runs)
  NarrativeDirector.ExecuteAyaChecksChat:
    1. Get unresponded messages from ChatBotManager
    2. Separate user messages from bot messages
    3. IF user messages exist -> process them (ALWAYS)
    4. ELSE IF user silence timer expired -> process bot messages (GATED)
    5. ELSE -> skip, Aya stays focused on drawing (NEW)

Timer State:
  _lastUserSpeechTime = Time.time (on every OnUserSpeakingStopped)
  UserSilenceDuration = Time.time - _lastUserSpeechTime
  IsUserSilent = UserSilenceDuration >= _userSilenceThreshold (default 120s)
```

## Open Questions

Things that couldn't be fully resolved:

1. **Should the 2-minute timer start from experience start or first user speech?**
   - What we know: The prior decisions say "Aya only responds to bot chat messages if the user has not spoken via PTT within a 2-minute silence window" and "the timer resets each time the user speaks"
   - What's unclear: If the user never speaks at all, should Aya eventually start engaging bots? With `_lastUserSpeechTime = Time.time` initialization, she will start engaging bots 2 minutes after the experience starts, which handles the passive viewer case.
   - Recommendation: Initialize to `Time.time` in Start(). This means: for the first 2 minutes, Aya focuses on drawing and greeting. After 2 minutes of no user PTT, she begins engaging with bot messages. If the user speaks at any point, the 2-minute window resets. This handles both active users (timer keeps resetting) and passive viewers (timer expires, bots get attention).

2. **AyaDialogue scene gating or just AyaChecksChat?**
   - What we know: The prior decisions focus on bot message injection. AyaDialogue scenes send director notes to steer Aya's topics.
   - What's unclear: Should AyaDialogue scenes also be gated when user is active? Or should the director notes still fire but be reframed to be less aggressive?
   - Recommendation: Do NOT gate AyaDialogue scenes. Instead, reframe director note content to be drawing-focused. AyaDialogue scenes ensure the narrative progresses on its time budget (important for reaching the reveal). The notes should guide topic flow without forcing Aya to monologue. Gate only AyaChecksChat, which is where Aya reads and responds to accumulated bot messages.

3. **What happens when user speaks DURING an AyaChecksChat response?**
   - What we know: The finish-first pattern in PushToTalkController already handles this -- if user presses PTT while Aya is speaking, it enters WaitingForAya and defers recording until Aya finishes.
   - What's unclear: After Aya finishes responding to a bot message (from AyaChecksChat), should the timer immediately gate the NEXT AyaChecksChat? Or does the user need to actually speak first?
   - Recommendation: The timer checks Time.time on each AyaChecksChat execution. If the user spoke during the previous AyaChecksChat response (resetting the timer), the next AyaChecksChat will see a fresh timer and skip bots. This is the natural behavior with no special handling needed.

## Sources

### Primary (HIGH confidence)
- LivestreamController.cs (Assets/AyaLiveStream/) -- lines 1-307: existing orchestrator with dead air timer pattern
- NarrativeDirector.cs (Assets/AyaLiveStream/) -- lines 397-441: ExecuteAyaChecksChat with user/bot message separation
- PushToTalkController.cs (Assets/AyaLiveStream/) -- lines 1-246: PTT state machine, OnUserSpeakingStopped usage
- ChatBotManager.cs (Assets/AyaLiveStream/) -- lines 1-582: burst loop, dynamic responses, tracked messages
- PersonaSession.cs (Packages/.../Runtime/) -- line 69: OnUserSpeakingStopped event declaration
- TrackedChatMessage.cs (Assets/AyaLiveStream/) -- ChatMessage.IsFromUser field
- ChatMessage.cs (Assets/AyaLiveStream/) -- line 17: IsFromUser flag, line 38-51: FromUser factory
- Beat asset files (Assets/AyaLiveStream/Data/) -- current director note content

### Secondary (MEDIUM confidence)
- Phase 16 RESEARCH.md -- established patterns for cross-system wiring, dead air detection, event subscription
- Phase 16 CONTEXT.md -- architecture decisions that constrain modifications
- Phase 14 CONTEXT.md -- PTT interaction model decisions

### Tertiary (LOW confidence)
- 2-minute threshold value -- prior decision specifies 2 minutes, but optimal feel may require tuning
- Director note reframing effectiveness -- depends on how Gemini interprets the changed tone

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH -- zero new dependencies, all modifications to existing code with verified patterns
- Architecture: HIGH -- the seams already exist (ExecuteAyaChecksChat user/bot split, PersonaSession events, LivestreamController timer pattern)
- Pitfalls: HIGH -- derived from line-by-line analysis of actual code paths
- Director note content: MEDIUM -- tone changes depend on Gemini's interpretation, may need iteration

**Research date:** 2026-02-17
**Valid until:** 2026-03-17 (stable; all components are local code, no external dependency changes expected)
