---
phase: 02-audio-pipeline
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - Packages/com.google.ai-embodiment/Runtime/AudioCapture.cs
autonomous: true

must_haves:
  truths:
    - "AudioCapture records from system default microphone at 16kHz mono"
    - "AudioCapture streams accumulated PCM chunks to a callback for sending to Gemini Live"
    - "Microphone permission is requested automatically before capture starts"
    - "Capture can be started and stopped cleanly without leaked resources"
    - "Capture accumulates at least 100ms (1600 samples) before invoking the send callback"
  artifacts:
    - path: "Packages/com.google.ai-embodiment/Runtime/AudioCapture.cs"
      provides: "Microphone capture MonoBehaviour with coroutine polling"
      contains: "class AudioCapture"
  key_links:
    - from: "AudioCapture.CaptureLoop"
      to: "Microphone.GetPosition"
      via: "coroutine polls mic position each frame"
      pattern: "Microphone\\.GetPosition"
    - from: "AudioCapture.CaptureLoop"
      to: "OnAudioCaptured callback"
      via: "fires callback with float[] chunk for PersonaSession to send"
      pattern: "OnAudioCaptured"
---

<objective>
Create the AudioCapture MonoBehaviour for microphone recording and streaming audio data to the session.

Purpose: AudioCapture is the input half of the audio pipeline. It handles platform-specific microphone permissions, records at 16kHz mono (Gemini's required input format), and delivers chunked PCM data via a callback that PersonaSession will wire to LiveSession.SendAudioAsync in Plan 02-03.

Output: One new C# file providing a clean mic capture component ready for PersonaSession integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-audio-pipeline/02-RESEARCH.md
@.planning/phases/02-audio-pipeline/02-CONTEXT.md
@Packages/com.google.ai-embodiment/Runtime/PersonaSession.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: AudioCapture -- microphone recording with coroutine polling and chunked output</name>
  <files>Packages/com.google.ai-embodiment/Runtime/AudioCapture.cs</files>
  <action>
Create `AudioCapture.cs` in namespace `AIEmbodiment`. This MonoBehaviour handles microphone capture and streams PCM float[] chunks via a callback.

**Fields:**
- `private AudioClip _micClip` -- looping 1-second mic recording buffer
- `private int _lastSamplePos` -- tracks read position in circular mic clip
- `private bool _isCapturing` -- guards the capture coroutine
- `private Coroutine _captureCoroutine` -- reference for stopping
- `private const int MIC_FREQUENCY = 16000` -- 16kHz as required by Gemini
- `private const int MIC_CLIP_LENGTH_SEC = 1` -- 1 second looping buffer
- `private const int CHUNK_SAMPLES = 1600` -- 100ms chunks (16000 * 0.1)

**Public API:**
- `event Action<float[]> OnAudioCaptured` -- fires with each 100ms chunk of 16kHz mono PCM. PersonaSession subscribes and forwards to SendAudioAsync.
- `event Action OnPermissionDenied` -- fires if user denies microphone permission.
- `void StartCapture()` -- requests mic permission (platform-specific), starts `Microphone.Start(null, loop:true, MIC_CLIP_LENGTH_SEC, MIC_FREQUENCY)`, launches coroutine. If already capturing, no-op.
- `void StopCapture()` -- stops coroutine, calls `Microphone.End(null)`, sets `_isCapturing = false`, resets `_lastSamplePos = 0`. If not capturing, no-op.

**StartCapture flow:**
1. If `_isCapturing`, return.
2. Start coroutine `RequestPermissionAndCapture()`.

**RequestPermissionAndCapture() coroutine:**
1. Platform-specific permission request (see Research Example 4):
   - `#if UNITY_ANDROID && !UNITY_EDITOR`: Use `Permission.HasUserAuthorizedPermission` / `Permission.RequestUserPermission` with PermissionCallbacks. Wait until responded. If denied, fire `OnPermissionDenied?.Invoke()`, yield break.
   - `#else` (Editor/Desktop): Use `Application.RequestUserAuthorization(UserAuthorization.Microphone)`. If denied, fire `OnPermissionDenied?.Invoke()`, yield break.
2. After permission granted: `_micClip = Microphone.Start(null, true, MIC_CLIP_LENGTH_SEC, MIC_FREQUENCY)`.
3. If `_micClip == null`: `Debug.LogError("AudioCapture: Microphone.Start returned null")`, yield break.
4. Wait until mic is actually recording: `while (!(Microphone.IsRecording(null))) yield return null;`
5. Set `_isCapturing = true`, `_lastSamplePos = 0`.
6. Enter `CaptureLoop()`.

**CaptureLoop() coroutine:**
```
float[] buffer = new float[CHUNK_SAMPLES]; // pre-allocate once
while (_isCapturing)
{
    yield return null; // poll every frame

    int currentPos = Microphone.GetPosition(null);
    if (currentPos == _lastSamplePos) continue;

    // Calculate samples available (handling wrap-around -- Research Pitfall 2)
    int samplesToRead;
    if (currentPos > _lastSamplePos)
        samplesToRead = currentPos - _lastSamplePos;
    else
        samplesToRead = (_micClip.samples - _lastSamplePos) + currentPos;

    // Accumulate at least one chunk (100ms = 1600 samples) to avoid flooding (Pitfall 6)
    if (samplesToRead < CHUNK_SAMPLES) continue;

    // Read and send in chunk-sized pieces
    while (samplesToRead >= CHUNK_SAMPLES)
    {
        _micClip.GetData(buffer, _lastSamplePos);
        _lastSamplePos = (_lastSamplePos + CHUNK_SAMPLES) % _micClip.samples;
        samplesToRead -= CHUNK_SAMPLES;

        // Copy to new array for callback (buffer is reused)
        float[] chunk = new float[CHUNK_SAMPLES];
        System.Array.Copy(buffer, chunk, CHUNK_SAMPLES);
        OnAudioCaptured?.Invoke(chunk);
    }
}
```

**OnDestroy:**
- If `_isCapturing`, call `StopCapture()`.

**Important from RESEARCH.md:**
- System default microphone only (`null` device parameter) -- CONTEXT.md decision
- 100ms minimum chunk accumulation prevents WebSocket flooding (Pitfall 6)
- Mic wrap-around handling is critical (Pitfall 2): when `currentPos < _lastSamplePos`, buffer has wrapped
- `Microphone.Start` returns null if permission denied on Android (Pitfall 7)
- AudioCapture is a raw data pipe -- no amplitude tracking or debug properties (CONTEXT.md decision)

**Do NOT:**
- Add device selection -- CONTEXT.md says system default only
- Add amplitude/volume tracking -- CONTEXT.md says raw data pipe
- Call SendAudioAsync directly -- AudioCapture fires a callback, PersonaSession wires the connection
- Use Update() for polling -- use coroutine (Research: "Coroutine with yield is cleaner")

**Android `using` directives note:**
Add `#if UNITY_ANDROID` around `using UnityEngine.Android;` to avoid compile errors on non-Android platforms.
  </action>
  <verify>
Open the file and verify:
1. MIC_FREQUENCY = 16000 (Gemini input requirement)
2. CHUNK_SAMPLES = 1600 (100ms at 16kHz -- Pitfall 6)
3. Wrap-around handled: `samplesToRead = (clipSamples - _lastSamplePos) + currentPos` when currentPos < _lastSamplePos
4. Permission handling has both Android and Editor/Desktop paths
5. OnAudioCaptured callback fires with copied float[] chunks
6. StopCapture calls Microphone.End(null) and resets state
7. OnDestroy calls StopCapture if capturing
  </verify>
  <done>AudioCapture.cs exists as a MonoBehaviour with StartCapture/StopCapture, cross-platform microphone permission handling, coroutine-based polling at 100ms chunk granularity, and OnAudioCaptured callback delivering 16kHz mono float[] chunks</done>
</task>

</tasks>

<verification>
- AudioCapture.cs handles mic permission for Android and Desktop/Editor
- Capture records at 16kHz mono matching Gemini input requirements
- Chunks are 1600 samples (100ms) to prevent WebSocket flooding
- Wrap-around handling prevents audio glitches at buffer boundary
- No file conflicts with Plan 02-01 (AudioPlayback/RingBuffer) -- these are independent new files
- No modifications to existing files -- PersonaSession integration deferred to Plan 02-03
</verification>

<success_criteria>
- AudioCapture.cs exists in Packages/com.google.ai-embodiment/Runtime/
- Records at 16kHz mono from system default microphone
- Handles mic permission on Android and Desktop/Editor
- Accumulates 100ms chunks before firing callback
- Properly handles Microphone.GetPosition wrap-around
- Clean start/stop lifecycle with OnDestroy safety net
</success_criteria>

<output>
After completion, create `.planning/phases/02-audio-pipeline/02-02-SUMMARY.md`
</output>
