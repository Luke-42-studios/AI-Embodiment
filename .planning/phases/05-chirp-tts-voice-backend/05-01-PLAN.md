---
phase: 05-chirp-tts-voice-backend
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Packages/com.google.ai-embodiment/Runtime/ChirpTTSClient.cs
  - Packages/com.google.ai-embodiment/Runtime/ChirpVoiceList.cs
autonomous: true

must_haves:
  truths:
    - "ChirpTTSClient can send text to Cloud TTS API and return PCM float[] audio"
    - "WAV header is stripped from response before PCM conversion"
    - "Custom/cloned voices use voiceClone.voiceCloningKey field instead of voice.name"
    - "SSML wrapping is applied for standard voices, plain text for custom voices"
    - "ChirpVoiceList provides all 30 Chirp 3 HD voice names and 47 language locales"
  artifacts:
    - path: "Packages/com.google.ai-embodiment/Runtime/ChirpTTSClient.cs"
      provides: "HTTP client for Cloud TTS synthesis"
      exports: ["SynthesizeAsync"]
    - path: "Packages/com.google.ai-embodiment/Runtime/ChirpVoiceList.cs"
      provides: "Static voice and language data for Inspector and runtime"
      exports: ["Voices", "Languages", "GetApiVoiceName"]
  key_links:
    - from: "ChirpTTSClient.cs"
      to: "texttospeech.googleapis.com/v1/text:synthesize"
      via: "UnityWebRequest POST with x-goog-api-key header"
      pattern: "UnityWebRequest.*texttospeech"
    - from: "ChirpTTSClient.cs"
      to: "Firebase.FirebaseApp.DefaultInstance.Options.ApiKey"
      via: "API key retrieval at construction"
      pattern: "Options\\.ApiKey"
---

<objective>
Create the ChirpTTSClient HTTP client and ChirpVoiceList static data for Cloud TTS Chirp 3 HD voice synthesis.

Purpose: These are the foundational building blocks for the Chirp TTS voice backend. ChirpTTSClient handles the HTTP request/response cycle with Cloud TTS, including authentication, JSON serialization, base64 decoding, WAV header stripping, and PCM conversion. ChirpVoiceList provides the complete inventory of 30 voices and 47 language locales as static data for both the custom Inspector dropdown (Plan 02) and runtime voice name resolution.

Output: Two new Runtime files -- ChirpTTSClient.cs and ChirpVoiceList.cs
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-chirp-tts-voice-backend/05-RESEARCH.md
@.planning/phases/05-chirp-tts-voice-backend/05-CONTEXT.md

Source files for reference:
@Packages/com.google.ai-embodiment/Runtime/AudioPlayback.cs
@Packages/com.google.ai-embodiment/Runtime/MainThreadDispatcher.cs
@Packages/com.google.ai-embodiment/Runtime/com.google.ai-embodiment.asmdef
</context>

<tasks>

<task type="auto">
  <name>Task 1: ChirpVoiceList static data</name>
  <files>Packages/com.google.ai-embodiment/Runtime/ChirpVoiceList.cs</files>
  <action>
Create a static class `ChirpVoiceList` in the `AIEmbodiment` namespace that provides:

1. **Voice data:** A static readonly array of all 30 Chirp 3 HD voice short names (friendly names for dropdown): Achernar, Achird, Algenib, Algieba, Alnilam, Aoede, Autonoe, Callirrhoe, Charon, Despina, Enceladus, Erinome, Fenrir, Gacrux, Iapetus, Kore, Laomedeia, Leda, Orus, Puck, Pulcherrima, Rasalgethi, Sadachbia, Sadaltager, Schedar, Sulafat, Umbriel, Vindemiatrix, Zephyr, Zubenelgenubi. Sorted alphabetically (they already are).

2. **Language data:** A static readonly array of language locale codes (display name + code pairs). Use a simple readonly struct `ChirpLanguage` with `Code` (e.g., "en-US") and `DisplayName` (e.g., "English (US)") properties. Include all GA locales: ar-XA, bg-BG, bn-IN, cmn-CN, cs-CZ, da-DK, de-DE, el-GR, en-AU, en-GB, en-IN, en-US, es-ES, es-US, et-EE, fi-FI, fr-CA, fr-FR, gu-IN, he-IL, hi-IN, hr-HR, hu-HU, id-ID, it-IT, ja-JP, kn-IN, ko-KR, lt-LT, lv-LV, ml-IN, mr-IN, nl-BE, nl-NL, pl-PL, pt-BR, ro-RO, ru-RU, sk-SK, sl-SI, sr-RS, sw-KE, ta-IN, te-IN, th-TH, tr-TR, vi-VN. Plus preview: pa-IN, yue-HK. Sorted by DisplayName.

3. **API name builder:** A static method `GetApiVoiceName(string languageCode, string voiceShortName)` that returns the full Cloud TTS voice name: `"{languageCode}-Chirp3-HD-{voiceShortName}"` (e.g., "en-US-Chirp3-HD-Achernar").

4. **Special constant:** A `public const string CustomVoice = "Custom"` string for the "Custom" dropdown option.

5. **Helper:** A static method `GetVoiceDisplayNames()` that returns a string array of all voice short names plus "Custom" as the last entry. This is for the Inspector dropdown.

Do NOT add Unity Editor dependencies -- this is a Runtime file used by both Editor and Runtime code.
  </action>
  <verify>File compiles without errors. Contains exactly 30 voice names and 47+ language entries. `GetApiVoiceName("en-US", "Achernar")` returns `"en-US-Chirp3-HD-Achernar"`.</verify>
  <done>ChirpVoiceList.cs exists with complete voice inventory, language list, API name builder, and Custom constant.</done>
</task>

<task type="auto">
  <name>Task 2: ChirpTTSClient HTTP client</name>
  <files>Packages/com.google.ai-embodiment/Runtime/ChirpTTSClient.cs</files>
  <action>
Create a plain C# class `ChirpTTSClient` in the `AIEmbodiment` namespace. NOT a MonoBehaviour (follows PacketAssembler pattern). This class handles HTTP requests to Cloud TTS.

**Constructor:** `ChirpTTSClient(string apiKey)` -- stores the API key. Caller obtains it via `Firebase.FirebaseApp.DefaultInstance.Options.ApiKey` and passes it in.

**Primary method:** `async Awaitable<float[]> SynthesizeAsync(string text, string voiceName, string languageCode, string voiceCloningKey = null)`

Implementation:
1. Build the JSON request body using string concatenation or StringBuilder (NOT JsonUtility -- it can't handle the nested voice/audioConfig structure cleanly). Use MiniJSON (`Google.MiniJSON.Json.Serialize`) if available, otherwise manual JSON building.
   - When `voiceCloningKey` is null or empty: standard voice request with `voice.languageCode` and `voice.name` (full API name from ChirpVoiceList.GetApiVoiceName). Use SSML wrapping: `input.ssml` with `<speak>{text}</speak>`.
   - When `voiceCloningKey` is NOT null/empty: custom voice request with `voice.languageCode` and `voice.voiceClone.voiceCloningKey`. Use plain text: `input.text` (NO SSML -- custom voices don't support it, per Research Pitfall 7).
   - Always include `audioConfig.audioEncoding: "LINEAR16"` and `audioConfig.sampleRateHertz: 24000`.

2. Create UnityWebRequest POST to `https://texttospeech.googleapis.com/v1/text:synthesize`:
   - Set `Content-Type: application/json; charset=utf-8` header
   - Set `x-goog-api-key: {apiKey}` header
   - Use `UploadHandlerRaw` for body bytes and `DownloadHandlerBuffer` for response
   - `await request.SendWebRequest()` (Unity 6 Awaitable pattern)

3. On failure: throw `System.Exception` with descriptive message including `request.error` and `request.downloadHandler.text` (for 403 "API not enabled" diagnostics per Pitfall 5).

4. On success: Parse response JSON to extract `audioContent` string (base64). Use MiniJSON or simple string parsing to find the value.

5. Decode base64: `System.Convert.FromBase64String(audioContent)`

6. Strip WAV header and convert to float[]:
   - Validate first 4 bytes are 0x52, 0x49, 0x46, 0x46 ("RIFF") -- if not, log warning and assume raw PCM (skip 0 bytes instead of 44).
   - Skip first 44 bytes (standard WAV header per Research Pitfall 1).
   - Convert remaining bytes from 16-bit signed little-endian to float: `BitConverter.ToInt16(bytes, offset) / 32768f` per sample.
   - Return the float array.

**IMPORTANT threading constraint:** UnityWebRequest MUST run on the main thread (Research Pitfall 3). The async Awaitable pattern in Unity 6 handles this correctly -- `await request.SendWebRequest()` captures the synchronization context. Do NOT use `Task.Run` or any background threading.

**Error event:** Add `public event Action<Exception> OnError` for non-throwing error reporting. The caller (PersonaSession) will subscribe to this.

**Dispose pattern:** Implement `IDisposable`. In `Dispose()`, set a `_disposed` flag. `SynthesizeAsync` checks `_disposed` at entry and returns null (or throws ObjectDisposedException).
  </action>
  <verify>File compiles without errors. Class implements IDisposable. SynthesizeAsync signature matches `Awaitable<float[]>`. JSON request building handles both standard and custom voice paths. WAV header stripping starts at byte 44 with RIFF validation.</verify>
  <done>ChirpTTSClient.cs exists as a plain C# class that sends text to Cloud TTS via UnityWebRequest, decodes base64 LINEAR16 response, strips WAV header, and returns PCM float[] at 24kHz.</done>
</task>

</tasks>

<verification>
- Both files are in `Packages/com.google.ai-embodiment/Runtime/` directory
- Both files use `namespace AIEmbodiment`
- ChirpTTSClient references ChirpVoiceList.GetApiVoiceName (or accepts pre-built voice name)
- No MonoBehaviour inheritance on either class
- No Editor-only dependencies (both are Runtime)
- UnityWebRequest usage is main-thread safe via Awaitable
</verification>

<success_criteria>
- ChirpVoiceList contains all 30 Chirp 3 HD voice names and 47+ language locales
- ChirpTTSClient.SynthesizeAsync handles standard voices (SSML), custom voices (plain text + voiceCloningKey), WAV header stripping, and PCM conversion
- Authentication uses x-goog-api-key header with Firebase API key
- Error handling includes descriptive messages for common failures (403, network errors)
</success_criteria>

<output>
After completion, create `.planning/phases/05-chirp-tts-voice-backend/05-01-SUMMARY.md`
</output>
