---
phase: 05-chirp-tts-voice-backend
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - Packages/com.google.ai-embodiment/Runtime/PersonaSession.cs
autonomous: true

must_haves:
  truths:
    - "When Chirp backend is selected, Gemini native audio is discarded (not routed to AudioPlayback)"
    - "Output transcription text is routed through ChirpTTSClient for synthesis"
    - "Synthesized Chirp PCM audio is enqueued to AudioPlayback via the existing ring buffer"
    - "Sentence-by-sentence mode synthesizes each SyncPacket text as it emits"
    - "Full-response mode buffers all text until turn end, then synthesizes once"
    - "TTS failure results in silent skip + error event, conversation continues"
    - "Gemini Live session stays in audio mode with output transcription (never text-only mode)"
  artifacts:
    - path: "Packages/com.google.ai-embodiment/Runtime/PersonaSession.cs"
      provides: "Chirp TTS routing in ProcessResponse and synthesis orchestration"
      contains: "ChirpTTSClient"
  key_links:
    - from: "PersonaSession.cs"
      to: "ChirpTTSClient.cs"
      via: "SynthesizeAsync call with SyncPacket text"
      pattern: "_chirpClient\\.SynthesizeAsync"
    - from: "PersonaSession.cs"
      to: "AudioPlayback.cs"
      via: "EnqueueAudio with Chirp PCM output"
      pattern: "_audioPlayback\\.EnqueueAudio"
    - from: "PersonaSession.cs"
      to: "PersonaConfig.cs"
      via: "voiceBackend and chirpSynthesisMode checks"
      pattern: "_config\\.voiceBackend.*ChirpTTS"
---

<objective>
Integrate ChirpTTSClient into PersonaSession to route AI text through Chirp TTS synthesis when the Chirp backend is selected, with support for both sentence-by-sentence and full-response synthesis modes.

Purpose: This is the critical wiring plan that makes Chirp TTS work end-to-end. PersonaSession.ProcessResponse must be modified to: (1) suppress Gemini native audio routing to AudioPlayback when Chirp is selected, (2) capture output transcription text, (3) route it through ChirpTTSClient, and (4) feed synthesized PCM back to AudioPlayback. The CRITICAL architectural constraint is that Gemini Live stays in audio mode -- we use output transcription (already captured by PacketAssembler) as the text source for Chirp synthesis.

Output: Modified PersonaSession.cs with Chirp TTS routing and synthesis orchestration
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-chirp-tts-voice-backend/05-RESEARCH.md
@.planning/phases/05-chirp-tts-voice-backend/05-CONTEXT.md
@.planning/phases/05-chirp-tts-voice-backend/05-01-SUMMARY.md
@.planning/phases/05-chirp-tts-voice-backend/05-02-SUMMARY.md

Source files (read these -- they contain the code you are modifying):
@Packages/com.google.ai-embodiment/Runtime/PersonaSession.cs
@Packages/com.google.ai-embodiment/Runtime/PersonaConfig.cs
@Packages/com.google.ai-embodiment/Runtime/ChirpTTSClient.cs
@Packages/com.google.ai-embodiment/Runtime/AudioPlayback.cs
@Packages/com.google.ai-embodiment/Runtime/PacketAssembler.cs
@Packages/com.google.ai-embodiment/Runtime/MainThreadDispatcher.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: PersonaSession Chirp TTS integration</name>
  <files>Packages/com.google.ai-embodiment/Runtime/PersonaSession.cs</files>
  <action>
Modify PersonaSession to support the Chirp TTS voice path. This is the largest change in the phase. Read the existing PersonaSession.cs carefully before modifying.

**New fields (add near existing private fields):**

```csharp
private ChirpTTSClient _chirpClient;
private readonly System.Text.StringBuilder _chirpTextBuffer = new System.Text.StringBuilder();
private bool _chirpSynthesizing;  // prevents overlapping synthesis requests
```

**Modify Connect() method:**

After `_packetAssembler.SetPacketCallback(HandleSyncPacket);` and AudioPlayback initialization, add Chirp client initialization:

```csharp
// Initialize Chirp TTS client when backend is ChirpTTS
if (_config.voiceBackend == VoiceBackend.ChirpTTS)
{
    string apiKey = Firebase.FirebaseApp.DefaultInstance.Options.ApiKey;
    _chirpClient = new ChirpTTSClient(apiKey);
    _chirpClient.OnError += HandleChirpError;
}
```

**CRITICAL: Do NOT change the LiveGenerationConfig.** The session MUST stay in `ResponseModality.Audio` mode with output transcription enabled. Do not add any conditional logic to switch to text mode. The native audio model rejects text-only mode (Research Pitfall 2). Gemini will produce audio that gets discarded when Chirp is selected -- this is by design.

**Modify ProcessResponse() -- audio routing section (lines ~558-588):**

Change the audio routing inside the `audioChunks != null && audioChunks.Count > 0` block:

```csharp
var audioChunks = response.AudioAsFloat;
if (audioChunks != null && audioChunks.Count > 0)
{
    // Only route Gemini native audio to playback when using GeminiNative backend
    if (_config.voiceBackend == VoiceBackend.GeminiNative && _audioPlayback != null)
    {
        foreach (var chunk in audioChunks)
        {
            _audioPlayback.EnqueueAudio(chunk);
        }
    }
    // NOTE: When ChirpTTS is selected, Gemini audio is intentionally discarded.
    // Audio playback is driven by ChirpTTSClient synthesis instead.

    // AI speaking state tracking -- keep for GeminiNative only
    if (_config.voiceBackend == VoiceBackend.GeminiNative && !_aiSpeaking)
    {
        _aiSpeaking = true;
        MainThreadDispatcher.Enqueue(() => OnAISpeakingStarted?.Invoke());
    }

    // Turn start detection unchanged (needed for PacketAssembler in both paths)
    if (!_turnStarted)
    {
        _turnStarted = true;
        MainThreadDispatcher.Enqueue(() => _packetAssembler?.StartTurn());
    }

    // Route audio to PacketAssembler ONLY for GeminiNative
    // (Chirp path: PacketAssembler gets text from transcription, audio from Chirp synthesis)
    if (_config.voiceBackend == VoiceBackend.GeminiNative)
    {
        foreach (var chunk in audioChunks)
        {
            var localChunk = chunk;
            MainThreadDispatcher.Enqueue(() => _packetAssembler?.AddAudio(localChunk));
        }
    }
}
```

**Modify ProcessResponse() -- TurnComplete section:**

After the existing `_packetAssembler?.FinishTurn()` call, add Chirp full-response synthesis trigger:

```csharp
if (content.TurnComplete)
{
    if (_aiSpeaking)
    {
        _aiSpeaking = false;
        MainThreadDispatcher.Enqueue(() => OnAISpeakingStopped?.Invoke());
    }
    MainThreadDispatcher.Enqueue(() => OnTurnComplete?.Invoke());

    _turnStarted = false;
    MainThreadDispatcher.Enqueue(() => _packetAssembler?.FinishTurn());

    // Chirp full-response mode: synthesize accumulated text on turn end
    if (_config.voiceBackend == VoiceBackend.ChirpTTS
        && _config.chirpSynthesisMode == ChirpSynthesisMode.FullResponse
        && _chirpTextBuffer.Length > 0)
    {
        string fullText = _chirpTextBuffer.ToString();
        _chirpTextBuffer.Clear();
        MainThreadDispatcher.Enqueue(() => SynthesizeAndEnqueue(fullText));
    }
}
```

**Modify ProcessResponse() -- OutputTranscription section:**

After the existing PacketAssembler routing for output transcription, add Chirp text capture:

```csharp
if (content.OutputTranscription.HasValue)
{
    string transcript = content.OutputTranscription.Value.Text;
    MainThreadDispatcher.Enqueue(() => OnOutputTranscription?.Invoke(transcript));

    // Turn start detection (existing, unchanged)
    if (!_turnStarted)
    {
        _turnStarted = true;
        MainThreadDispatcher.Enqueue(() => _packetAssembler?.StartTurn());
    }

    // Route to PacketAssembler (existing, unchanged)
    string transcriptForAssembler = transcript;
    MainThreadDispatcher.Enqueue(() => _packetAssembler?.AddTranscription(transcriptForAssembler));

    // Chirp TTS: capture text for synthesis
    if (_config.voiceBackend == VoiceBackend.ChirpTTS)
    {
        _chirpTextBuffer.Append(transcript);
    }
}
```

**Modify HandleSyncPacket():**

Add sentence-by-sentence Chirp synthesis. When Chirp backend is selected and synthesis mode is SentenceBySentence, synthesize each TextAudio SyncPacket's text:

```csharp
private void HandleSyncPacket(SyncPacket packet)
{
    // Chirp sentence-by-sentence synthesis: synthesize text from each SyncPacket
    if (_config.voiceBackend == VoiceBackend.ChirpTTS
        && _config.chirpSynthesisMode == ChirpSynthesisMode.SentenceBySentence
        && packet.Type == SyncPacketType.TextAudio
        && !string.IsNullOrEmpty(packet.Text))
    {
        SynthesizeAndEnqueue(packet.Text);
    }

    // Existing function dispatch (unchanged)
    if (packet.Type == SyncPacketType.FunctionCall && !string.IsNullOrEmpty(packet.FunctionName))
    {
        DispatchFunctionCall(packet);
    }

    // Always forward to developer subscribers (unchanged)
    OnSyncPacket?.Invoke(packet);
}
```

**New method: SynthesizeAndEnqueue (async void, runs on main thread):**

```csharp
/// <summary>
/// Synthesizes text via Chirp TTS and enqueues the resulting PCM audio for playback.
/// Runs on the main thread (required by UnityWebRequest).
/// On failure: logs error, fires OnError, but conversation continues (silent skip per CONTEXT.md).
/// </summary>
private async void SynthesizeAndEnqueue(string text)
{
    if (_chirpClient == null || _audioPlayback == null || string.IsNullOrEmpty(text)) return;

    try
    {
        // Determine voice parameters from config
        string voiceCloningKey = _config.IsCustomChirpVoice ? _config.voiceCloningKey : null;
        string voiceName = _config.IsCustomChirpVoice ? _config.customVoiceName : _config.chirpVoiceShortName;

        // Fire AI speaking started on first synthesis of a turn
        if (!_aiSpeaking)
        {
            _aiSpeaking = true;
            OnAISpeakingStarted?.Invoke();
        }

        float[] pcm = await _chirpClient.SynthesizeAsync(
            text,
            voiceName,
            _config.chirpLanguageCode,
            voiceCloningKey
        );

        if (pcm != null && pcm.Length > 0 && _audioPlayback != null)
        {
            _audioPlayback.EnqueueAudio(pcm);
        }
    }
    catch (Exception ex)
    {
        // Silent skip + error event per CONTEXT.md decision
        // Text still displays via OnSyncPacket, conversation continues
        OnError?.Invoke(ex);
        Debug.LogWarning($"PersonaSession: Chirp TTS synthesis failed (text still displayed): {ex.Message}");
    }
}
```

**New method: HandleChirpError:**

```csharp
private void HandleChirpError(Exception ex)
{
    MainThreadDispatcher.Enqueue(() =>
    {
        OnError?.Invoke(ex);
        Debug.LogWarning($"PersonaSession: Chirp TTS error: {ex.Message}");
    });
}
```

**Modify Disconnect():**

After `_packetAssembler = null;`, add Chirp client disposal:

```csharp
if (_chirpClient != null)
{
    _chirpClient.OnError -= HandleChirpError;
    _chirpClient.Dispose();
    _chirpClient = null;
}
_chirpTextBuffer.Clear();
_aiSpeaking = false;
```

**Modify OnDestroy():**

Add Chirp client disposal before existing CTS cancellation:

```csharp
_chirpClient?.Dispose();
_chirpClient = null;
```

**Modify Interrupt handling:**

In the `content.Interrupted` block, add Chirp text buffer clearing:

```csharp
if (content.Interrupted)
{
    // Existing interrupt handling (unchanged)
    if (_audioPlayback != null)
    {
        _audioPlayback.ClearBuffer();
    }
    if (_aiSpeaking)
    {
        _aiSpeaking = false;
        MainThreadDispatcher.Enqueue(() => OnAISpeakingStopped?.Invoke());
    }
    MainThreadDispatcher.Enqueue(() => OnInterrupted?.Invoke());

    _turnStarted = false;
    MainThreadDispatcher.Enqueue(() => _packetAssembler?.CancelTurn());

    // Clear Chirp text buffer on interruption
    _chirpTextBuffer.Clear();
}
```

**Add using directive:** Add `using System.Text;` at the top if not already present (for StringBuilder).

**Key architectural points to remember:**
- Do NOT change LiveGenerationConfig. Gemini stays in audio mode. Audio is discarded for Chirp path.
- SynthesizeAndEnqueue is async void (fire-and-forget from callback context). Error handling is inside the method.
- For sentence-by-sentence: synthesis is triggered from HandleSyncPacket (main thread, via PacketAssembler callback).
- For full-response: synthesis is triggered from TurnComplete (main thread, via MainThreadDispatcher).
- AI speaking events are driven by Chirp synthesis lifecycle (not Gemini audio arrival) when Chirp is selected.
- The Chirp text buffer is SEPARATE from PacketAssembler's text buffer. PacketAssembler handles sentence segmentation for SyncPacket emission. The Chirp text buffer accumulates ALL text for full-response mode.
  </action>
  <verify>
File compiles without errors. The following code paths exist:
1. GeminiNative path: audio routes to AudioPlayback and PacketAssembler (unchanged from before)
2. ChirpTTS + SentenceBySentence: HandleSyncPacket calls SynthesizeAndEnqueue per sentence
3. ChirpTTS + FullResponse: TurnComplete triggers SynthesizeAndEnqueue with accumulated text
4. Chirp client initialized in Connect(), disposed in Disconnect() and OnDestroy()
5. Gemini audio discarded (not routed to AudioPlayback) when ChirpTTS selected
6. LiveGenerationConfig unchanged (still ResponseModality.Audio)
  </verify>
  <done>PersonaSession routes AI output transcription through ChirpTTSClient when Chirp backend is selected, with both sentence-by-sentence and full-response synthesis modes working. Gemini native audio is discarded in Chirp path. TTS failures result in silent skip with error event. Clean disposal on disconnect and destroy.</done>
</task>

</tasks>

<verification>
- PersonaSession compiles with all changes
- GeminiNative path is completely unchanged (backward compatible)
- ChirpTTS path: Gemini audio discarded, transcription text drives Chirp synthesis
- Sentence-by-sentence: each SyncPacket text triggers synthesis
- Full-response: all text accumulated until TurnComplete, then synthesized once
- Error handling: TTS failure = silent skip + error event, text displays normally
- Chirp client lifecycle: created in Connect(), disposed in Disconnect()/OnDestroy()
- No changes to LiveGenerationConfig (Gemini stays in audio mode)
- Interrupt handling clears Chirp text buffer
</verification>

<success_criteria>
- When VoiceBackend.ChirpTTS is selected, Gemini native audio is NOT routed to AudioPlayback
- Output transcription text is captured and routed through ChirpTTSClient.SynthesizeAsync
- Synthesized PCM audio is enqueued to AudioPlayback via existing ring buffer
- Both synthesis modes work: sentence-by-sentence (via HandleSyncPacket) and full-response (via TurnComplete)
- TTS failures are gracefully handled (silent skip + error event)
- GeminiNative path remains completely unchanged
</success_criteria>

<output>
After completion, create `.planning/phases/05-chirp-tts-voice-backend/05-03-SUMMARY.md`
</output>
