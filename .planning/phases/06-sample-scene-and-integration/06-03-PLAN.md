---
phase: 06-sample-scene-and-integration
plan: 03
type: execute
wave: 3
depends_on: ["06-02"]
files_modified: []
autonomous: false

must_haves:
  truths:
    - "Sample scene loads in Unity Editor without errors"
    - "Developer can import the sample via Package Manager > AI Embodiment > Samples > Aya Live Stream > Import"
    - "Running the scene shows the dark-themed chat panel with Aya's name, speaking indicator, chat log, status label, and push-to-talk button"
    - "PersonaSession has PersonaConfig, AudioCapture, and AudioPlayback assigned"
    - "AyaSampleController has references to PersonaSession, AyaChatUI, intro AudioSource"
    - "AyaChatUI has references to UIDocument and PersonaSession"
  artifacts: []
  key_links:
    - from: "AyaLiveStream.unity scene"
      to: "AyaSampleController.cs"
      via: "MonoBehaviour component on GameObject"
      pattern: "scene wiring"
    - from: "AyaLiveStream.unity scene"
      to: "AyaPersonaConfig.asset"
      via: "PersonaSession._config SerializeField"
      pattern: "scene wiring"
    - from: "AyaLiveStream.unity scene"
      to: "PanelSettings.asset"
      via: "UIDocument panel settings reference"
      pattern: "scene wiring"
---

<objective>
Create Unity Editor assets (scene, PersonaConfig, PanelSettings) that cannot be hand-authored, and verify the complete sample works end-to-end.

Purpose: The scene file, ScriptableObject assets, and PanelSettings are binary/YAML assets that must be created through the Unity Editor. This checkpoint ensures all code from Plans 01-02 is wired together into a runnable scene.
Output: A complete, runnable AyaLiveStream sample scene with all components wired.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-sample-scene-and-integration/06-RESEARCH.md
@.planning/phases/06-sample-scene-and-integration/06-01-SUMMARY.md
@.planning/phases/06-sample-scene-and-integration/06-02-SUMMARY.md
</context>

<tasks>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Plans 01 and 02 created all code files for the Aya Live Stream sample:
- package.json with samples entry
- AyaLiveStream.asmdef with assembly references
- UI/AyaPanel.uxml (layout) and UI/AyaPanel.uss (styling)
- AyaChatUI.cs (UI controller)
- AyaSampleController.cs (main controller with functions, intro, PTT, goals)

The following assets MUST be created in the Unity Editor because they are binary/YAML that cannot be reliably hand-authored:

**Step 1: Create the PersonaConfig asset**
1. Open Unity Editor
2. Navigate to `Packages/com.google.ai-embodiment/Samples~/AyaLiveStream/` in the Project window
   - NOTE: If Samples~ is hidden, you may need to import the sample first (Package Manager > AI Embodiment > Samples > Import) or navigate via file system
3. Right-click > Create > AI Embodiment > Persona Config
4. Name it `AyaPersonaConfig`
5. Configure in Inspector:
   - Display Name: `Aya`
   - Archetype: `The Bubbly Digital Artist`
   - Backstory: `You've been drawing since you could hold a pencil. You started sharing your art on YouTube 5 years ago, and it grew into an amazing community. Your style is colorful and expressive, influenced by anime and pop art. You believe everyone has creativity in them, and your mission is to share the joy of creating. You're live right now, drawing on stream, talking to your whole community. Say things like "Oh chat!", "you guys", "everyone". Keep it concise - you're multitasking and streaming. NEVER use emojis - your speech is converted to audio and emojis get read aloud awkwardly.`
   - Personality Traits: `creative`, `bubbly`, `encouraging`, `curious`, `tech-savvy`, `quirky`, `positive`
   - Speech Patterns: `Uses "totally", "awesome", "honestly", "literally obsessed". Avoid: "lit", "cap", "slay".`
   - Model Name: `gemini-2.5-flash-native-audio-preview-12-2025` (default)
   - Temperature: `0.8`
   - Voice Backend: `GeminiNative` (default -- simplest for demo)
   - Gemini Voice Name: `Puck`

**Step 2: Create the PanelSettings asset**
1. In the same Samples~/AyaLiveStream/ folder
2. Right-click > Create > UI Toolkit > Panel Settings Asset
3. Name it `PanelSettings`
4. Leave defaults (or adjust Scale Mode to "Scale With Screen Size" if desired)

**Step 3: Create the scene**
1. File > New Scene (Basic template)
2. Save as `AyaLiveStream.unity` in `Packages/com.google.ai-embodiment/Samples~/AyaLiveStream/`
3. Set camera background to solid color (dark -- rgb 24,24,32 matches UI theme)

**Step 4: Set up GameObjects in the scene**

Create this hierarchy:

```
AyaSession (empty GameObject)
  Components:
  - PersonaSession
    - Config: drag AyaPersonaConfig.asset
    - Audio Capture: drag AudioCapture component (add below)
    - Audio Playback: drag AudioPlayback component (add below)
  - AudioCapture
  - AudioPlayback (requires AudioSource -- auto-added)
    - The AudioSource auto-added by AudioPlayback is for AI streaming voice
  - AudioSource (ADD A SECOND AudioSource manually for intro audio)

AyaUI (empty GameObject)
  Components:
  - UIDocument
    - Panel Settings: drag PanelSettings.asset
    - Source Asset: drag UI/AyaPanel.uxml
  - AyaChatUI
    - UI Document: drag the UIDocument component (same GameObject)
    - Session: drag AyaSession's PersonaSession component

AyaController (empty GameObject)
  Components:
  - AyaSampleController
    - Session: drag AyaSession's PersonaSession component
    - Chat UI: drag AyaUI's AyaChatUI component
    - Intro Audio Source: drag AyaSession's SECOND AudioSource (NOT the one from AudioPlayback)
    - Intro Clip: leave empty (no audio asset yet -- null check in code handles this gracefully)
```

**Step 5: Verify the scene**
1. Enter Play mode
2. You should see the dark-themed chat panel with:
   - "Aya" name label with gray indicator dot
   - Empty chat log area
   - Status showing "Aya's intro playing..." then "Going live..." then "Connecting..."
   - "Hold to Talk" button at the bottom
3. If Firebase is configured with a valid google-services.json, it should connect and you can test:
   - Hold spacebar to talk
   - See user transcription appear in blue
   - See Aya's response appear in purple
   - See function call events appear in gray italic (e.g., "[Emote: wave]")
   - After 3 exchanges, see "[Goal activated: Steer toward character life stories]"
4. If Firebase is NOT configured, you'll see an error in the status -- that's expected. The UI layout and code wiring are the main verification targets.

**Step 6 (optional): Create a placeholder intro audio**
If you want the intro flow to work, create or record a short audio clip (2-5 seconds) and assign it to AyaSampleController's Intro Clip field. The code handles null gracefully with a 1-second pause fallback.
  </what-built>
  <how-to-verify>
1. Open the AyaLiveStream scene in Unity Editor -- no compile errors in Console
2. Verify all component references are wired (no "None" on required fields):
   - PersonaSession: Config = AyaPersonaConfig, AudioCapture and AudioPlayback assigned
   - AyaChatUI: UIDocument and Session assigned
   - AyaSampleController: Session, ChatUI, IntroAudioSource assigned
3. Enter Play mode:
   - Dark chat panel renders with correct layout (header, chat log, footer)
   - Status label updates (shows intro then connecting sequence)
   - Push-to-talk button visible
   - No NullReferenceExceptions in Console
4. If Firebase configured: verify full conversational flow with voice, text, and function calls
  </how-to-verify>
  <resume-signal>Type "approved" when the scene works, or describe any issues encountered.</resume-signal>
</task>

</tasks>

<verification>
1. AyaLiveStream.unity scene exists and loads without errors
2. AyaPersonaConfig.asset exists with Aya's persona data configured
3. PanelSettings.asset exists and is assigned to UIDocument
4. All Inspector references are wired (no null SerializeField warnings)
5. Play mode shows the chat panel UI rendered correctly
6. Code compiles with no errors (asmdef references correct)
</verification>

<success_criteria>
- Scene loads and enters Play mode without compile errors or NullReferenceExceptions
- Chat panel UI renders with dark theme, Aya name, speaking indicator, chat log, status label, and push-to-talk button
- Status label updates through intro -> connecting sequence
- Component references all wired in Inspector
- If Firebase configured: full conversation works with voice, text, function calls, and goal injection after 3 exchanges
</success_criteria>

<output>
After completion, create `.planning/phases/06-sample-scene-and-integration/06-03-SUMMARY.md`
</output>
