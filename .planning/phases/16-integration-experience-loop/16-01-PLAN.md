---
phase: 16-integration-experience-loop
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Assets/AyaLiveStream/LivestreamController.cs
  - Assets/AyaLiveStream/FactTracker.cs
  - Assets/AyaLiveStream/AyaTranscriptBuffer.cs
  - Assets/AyaLiveStream/LivestreamUI.cs
  - Assets/AyaLiveStream/UI/LivestreamPanel.uxml
  - Assets/AyaLiveStream/UI/LivestreamPanel.uss
autonomous: true

must_haves:
  truths:
    - "LivestreamController initializes all subsystems and waits for PersonaSession.Connected before starting the experience"
    - "A loading state is visible while connecting, followed by a going live transition moment"
    - "FactTracker stores and retrieves string-keyed boolean facts"
    - "AyaTranscriptBuffer accumulates Aya speech turns and returns recent turns as formatted text"
  artifacts:
    - path: "Assets/AyaLiveStream/LivestreamController.cs"
      provides: "Top-level orchestrator MonoBehaviour with SerializeField references to all subsystems"
      contains: "class LivestreamController"
    - path: "Assets/AyaLiveStream/FactTracker.cs"
      provides: "Shared fact dictionary for cross-system coherence"
      contains: "class FactTracker"
    - path: "Assets/AyaLiveStream/AyaTranscriptBuffer.cs"
      provides: "Ring buffer of Aya transcript turns for prompt enrichment"
      contains: "class AyaTranscriptBuffer"
    - path: "Assets/AyaLiveStream/LivestreamUI.cs"
      provides: "UI methods for loading state, going live, and thinking indicator"
      exports: ["SetLoadingState", "ShowGoingLive", "ShowThinkingIndicator"]
  key_links:
    - from: "Assets/AyaLiveStream/LivestreamController.cs"
      to: "PersonaSession"
      via: "SerializeField + event subscription"
      pattern: "_session\\.On(OutputTranscription|TurnComplete|AISpeakingStarted|StateChanged)"
    - from: "Assets/AyaLiveStream/LivestreamController.cs"
      to: "NarrativeDirector"
      via: "SerializeField + StartNarrative call"
      pattern: "_narrativeDirector\\.StartNarrative"
    - from: "Assets/AyaLiveStream/LivestreamController.cs"
      to: "ChatBotManager"
      via: "SerializeField + StartBursts/StopBursts calls"
      pattern: "_chatBotManager\\.(StartBursts|StopBursts)"
---

<objective>
Create the LivestreamController orchestrator, FactTracker, AyaTranscriptBuffer, and UI extensions that form the foundation for the full experience loop.

Purpose: LivestreamController replaces AyaSampleController as the root controller for the livestream scene. It holds [SerializeField] references to all subsystems, initializes them with a connection-wait gate, and provides the "going live" transition experience. FactTracker and AyaTranscriptBuffer are plain C# objects created in Start() that enable cross-system context injection in Plan 02.

Output: 3 new C# files (LivestreamController, FactTracker, AyaTranscriptBuffer) + modified LivestreamUI with loading/going-live/thinking methods + UXML/USS additions for new UI elements.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-integration-experience-loop/16-RESEARCH.md

@Assets/AyaLiveStream/AyaSampleController.cs
@Assets/AyaLiveStream/NarrativeDirector.cs
@Assets/AyaLiveStream/ChatBotManager.cs
@Assets/AyaLiveStream/PushToTalkController.cs
@Assets/AyaLiveStream/SceneTransitionHandler.cs
@Assets/AyaLiveStream/LivestreamUI.cs
@Assets/AyaLiveStream/AnimationConfig.cs
@Assets/AyaLiveStream/UI/LivestreamPanel.uxml
@Assets/AyaLiveStream/UI/LivestreamPanel.uss
</context>

<tasks>

<task type="auto">
  <name>Task 1: FactTracker, AyaTranscriptBuffer, and LivestreamUI extensions</name>
  <files>
    Assets/AyaLiveStream/FactTracker.cs
    Assets/AyaLiveStream/AyaTranscriptBuffer.cs
    Assets/AyaLiveStream/LivestreamUI.cs
    Assets/AyaLiveStream/UI/LivestreamPanel.uxml
    Assets/AyaLiveStream/UI/LivestreamPanel.uss
  </files>
  <action>
    Create FactTracker.cs in Assets/AyaLiveStream/ (namespace AIEmbodiment.Samples):
    - Plain C# class (NOT MonoBehaviour) with Dictionary&lt;string, bool&gt; backing store
    - SetFact(string factId, bool value = true) -- stores fact, Debug.Log on change
    - HasFact(string factId) -- returns bool (false if missing)
    - GetFactsSummary() -- returns StringBuilder of all true facts as "- factId" lines, empty string if none
    - Keep it minimal (Pitfall 7 from research: avoid scope creep). Target 5-8 facts for the whole experience.

    Create AyaTranscriptBuffer.cs in Assets/AyaLiveStream/ (namespace AIEmbodiment.Samples):
    - Plain C# class (NOT MonoBehaviour) with List&lt;string&gt; turns and StringBuilder currentTurn
    - Constructor takes int maxTurns = 5
    - AppendText(string text) -- appends to _currentTurn StringBuilder
    - CompleteTurn() -- if _currentTurn.Length > 0, adds to _turns list, clears builder, trims list if > maxTurns (RemoveAt(0))
    - GetRecentTurns(int count) -- returns last N turns formatted as bullet points: '- "turn text"' per line. Returns empty string if no turns.
    - Use Mathf.Max(0, _turns.Count - count) for start index

    Extend LivestreamUI.cs with 3 new methods (add to existing class, do NOT rewrite existing methods):
    - SetLoadingState(bool loading) -- shows/hides a loading overlay. When true: show "Connecting..." text in a centered overlay. When false: hide the overlay.
    - ShowGoingLive() -- changes the loading overlay text to "GOING LIVE!" with an emphasis CSS class, auto-hides after 1.5s via Awaitable (same pattern as ShowToast).
    - ShowThinkingIndicator(bool show) -- toggles a small "Aya is thinking..." label below the aya-indicator. Use CSS class toggle (thinking-indicator--visible/hidden).

    Add new UI elements to LivestreamPanel.uxml:
    - A loading-overlay VisualElement (centered over the main-content area, position: absolute, covers full panel) containing a Label "loading-text" with text "Connecting..."
    - A thinking-indicator Label below the aya-indicator in the aya-header, text "Aya is thinking...", initially hidden

    Add USS styles for:
    - .loading-overlay: position absolute, top/bottom/left/right 0, background-color rgba(24,24,32,0.9), justify-content center, align-items center, display flex
    - .loading-overlay--hidden: display none
    - .loading-text: color rgb(180,180,200), font-size 16px
    - .loading-text--live: color rgb(100,255,100), font-size 24px, -unity-font-style bold (for "GOING LIVE!" state)
    - .thinking-indicator: color rgb(180,180,200), font-size 10px, -unity-font-style italic, margin-left 16px, opacity 0, transition opacity 300ms
    - .thinking-indicator--visible: opacity 1

    In LivestreamUI.OnEnable(), query and store references to: _loadingOverlay, _loadingText, _thinkingIndicator.
  </action>
  <verify>
    Open each .cs file and confirm: no compile errors (check syntax), correct namespace (AIEmbodiment.Samples), correct class structure. Verify UXML has the new elements (loading-overlay, thinking-indicator). Verify USS has all new style classes. Verify LivestreamUI has the 3 new methods plus stored element references.
  </verify>
  <done>
    FactTracker provides SetFact/HasFact/GetFactsSummary. AyaTranscriptBuffer provides AppendText/CompleteTurn/GetRecentTurns. LivestreamUI has SetLoadingState, ShowGoingLive, ShowThinkingIndicator methods with corresponding UXML elements and USS styles.
  </done>
</task>

<task type="auto">
  <name>Task 2: LivestreamController orchestrator with initialization, event wiring, and shutdown</name>
  <files>
    Assets/AyaLiveStream/LivestreamController.cs
  </files>
  <action>
    Create LivestreamController.cs in Assets/AyaLiveStream/ (namespace AIEmbodiment.Samples):

    [SerializeField] fields (mirroring AyaSampleController + additions):
    - PersonaSession _session
    - NarrativeDirector _narrativeDirector
    - ChatBotManager _chatBotManager
    - PushToTalkController _pttController
    - SceneTransitionHandler _sceneTransitionHandler
    - LivestreamUI _livestreamUI
    - AnimationConfig _animationConfig
    - float _connectionTimeout = 15f (Header "Configuration")
    - float _deadAirThreshold = 10f
    - float _thinkingIndicatorDelay = 5f

    Private fields:
    - AyaTranscriptBuffer _ayaTranscriptBuffer
    - FactTracker _factTracker
    - float _lastOutputTime
    - bool _running
    - bool _thinkingShown

    Start():
    1. Create _ayaTranscriptBuffer = new AyaTranscriptBuffer(maxTurns: 5)
    2. Create _factTracker = new FactTracker()
    3. Subscribe to PersonaSession events (store handler references for clean unsubscription like NarrativeDirector does):
       - OnOutputTranscription -> _ayaTranscriptBuffer.AppendText(text) AND update _livestreamUI.UpdateAyaTranscript(text)
       - OnTurnComplete -> _ayaTranscriptBuffer.CompleteTurn() AND _livestreamUI.CompleteAyaTurn()
       - OnAISpeakingStarted -> _lastOutputTime = Time.time AND _livestreamUI.ShowThinkingIndicator(false) AND _thinkingShown = false
       - OnFunctionError -> Debug.LogError (same pattern as AyaSampleController.HandleFunctionError)
    4. Register functions (copy RegisterFunctions pattern from AyaSampleController -- play_animation from AnimationConfig, with toast via _livestreamUI.ShowToast)
    5. _ = InitializeAndStart()

    InitializeAndStart() (async Awaitable):
    1. _running = true
    2. _livestreamUI.SetLoadingState(true)
    3. _session.Connect()
    4. Poll for connection with timeout (see 16-RESEARCH.md Pattern 1):
       - While _session.State != SessionState.Connected && elapsed < _connectionTimeout
       - If _session.State == SessionState.Error -> log error, hide loading, return
       - await Awaitable.WaitForSecondsAsync(0.1f, destroyCancellationToken)
    5. If timed out: Debug.LogWarning graceful degradation message, hide loading, start bots only (no narrative)
    6. On success:
       - _livestreamUI.SetLoadingState(false)
       - _livestreamUI.ShowGoingLive()
       - await Awaitable.WaitForSecondsAsync(1.5f, destroyCancellationToken) -- let "GOING LIVE!" register
       - _chatBotManager.StartBursts()
       - _narrativeDirector.StartNarrative()
       - _lastOutputTime = Time.time
       - _ = MonitorDeadAir() -- fire and forget the background monitor
    7. Wrap in try/catch (OperationCanceledException) { }

    MonitorDeadAir() (async Awaitable):
    - While _running loop with try/catch OperationCanceledException
    - Check Time.time - _lastOutputTime every 1 second
    - If silenceDuration >= _thinkingIndicatorDelay && !_thinkingShown -> _livestreamUI.ShowThinkingIndicator(true), _thinkingShown = true
    - If silenceDuration >= _deadAirThreshold -> reset _lastOutputTime to Time.time, hide thinking indicator, reset _thinkingShown. Log "[LivestreamController] Dead air detected, bots will re-engage." The ChatBotManager burst loop naturally fires -- no explicit trigger needed.
    - IMPORTANT: also update _lastOutputTime when ChatBotManager posts a message. The simplest approach: subscribe to a new event or check in the dead air loop. For now, just track Aya output time. Bot messages are visual-only and don't reset the dead air timer (dead air means Aya silence, not total silence).

    HandleNarrativeComplete():
    - Subscribe to _narrativeDirector.OnAllBeatsComplete in Start()
    - _running = false
    - _chatBotManager.StopBursts()
    - _livestreamUI.ShowThinkingIndicator(false)
    - SceneTransitionHandler already handles Disconnect + scene load (subscribed to OnAllBeatsComplete in its own OnEnable)

    OnDestroy():
    - _running = false
    - Unsubscribe ALL PersonaSession event handlers (OnOutputTranscription, OnTurnComplete, OnAISpeakingStarted, OnFunctionError)
    - Unsubscribe _narrativeDirector.OnAllBeatsComplete
    - Follow exact pattern from NarrativeDirector.OnDestroy (null check on _session, null check on handler references)

    CRITICAL ANTI-PATTERNS TO AVOID:
    - Do NOT use GetComponent or FindObjectOfType -- all references via [SerializeField]
    - Do NOT call _session.StartListening/StopListening -- PushToTalkController handles that
    - Do NOT send SendText -- NarrativeDirector handles that
    - Do NOT manipulate ChatBotManager._running -- use StartBursts/StopBursts only
    - Do NOT duplicate Update() PTT handling from AyaSampleController -- PushToTalkController owns that
  </action>
  <verify>
    Open LivestreamController.cs and verify: all [SerializeField] fields declared, Start() creates context objects and subscribes events, InitializeAndStart() polls for connection then starts subsystems in order, MonitorDeadAir() runs background silence detection, HandleNarrativeComplete() does orderly shutdown, OnDestroy() unsubscribes all events. No compile errors in syntax. No direct field manipulation of other subsystems.
  </verify>
  <done>
    LivestreamController.cs compiles, holds all subsystem references, initializes with connection wait + "going live" transition, wires AyaTranscriptBuffer to PersonaSession events, runs dead air monitor, performs orderly shutdown on OnAllBeatsComplete, and cleans up all subscriptions in OnDestroy.
  </done>
</task>

</tasks>

<verification>
- FactTracker.cs exists with SetFact, HasFact, GetFactsSummary
- AyaTranscriptBuffer.cs exists with AppendText, CompleteTurn, GetRecentTurns
- LivestreamUI.cs has SetLoadingState, ShowGoingLive, ShowThinkingIndicator + element references
- LivestreamPanel.uxml has loading-overlay and thinking-indicator elements
- LivestreamPanel.uss has all new style classes
- LivestreamController.cs exists with all SerializeField references, initialization sequence, dead air monitor, orderly shutdown
- No file in this plan conflicts with files in Plan 02 or 03 (LivestreamUI is only modified in Plan 01; NarrativeDirector, ChatBotManager, NarrativeBeatConfig are modified in Plan 02; CreateBeatAssets is modified in Plan 03)
</verification>

<success_criteria>
All 6 files created/modified. LivestreamController is the sole new orchestrator for the livestream scene. FactTracker and AyaTranscriptBuffer exist as injectable context providers. LivestreamUI has loading/going-live/thinking UI capability. The foundation is ready for Plan 02 to wire cross-system context injection.
</success_criteria>

<output>
After completion, create `.planning/phases/16-integration-experience-loop/16-01-SUMMARY.md`
</output>
